{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b5ed144-aadd-4a9c-a195-91b36e1ac9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## “Thank you to arXiv for use of its open access interoperability.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1d507d25-5c7a-41d3-9ec5-e82b8bdcaf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib, urllib.request\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3f8eec99-aa0c-403e-8af2-13ff7d89d130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_articles_of_day(day=None, num_articles=10):\n",
    "    \"\"\"\n",
    "    Downloads the titles and summaries of a given date in the condensed matter category. \n",
    "    If no inputs are given, it will do today's date and 10 articles\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    day : date.time format\n",
    "        A given date\n",
    "    num_articles : int\n",
    "                    The number of articles requested\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    titles : bs4 ResultSet\n",
    "            Contains all titles requested, can be indexed with []\n",
    "    summaries : bs4 ResultSet\n",
    "                Contains all abstracts belonging to the titles. \n",
    "    \n",
    "    \"\"\"\n",
    "    if day==None:\n",
    "        day = date.today()\n",
    "\n",
    "    tomorrow=day+datetime.timedelta(days=1)\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:condensed%20matter&submittedDate:[{day}+TO+{tomorrow}]&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending'\n",
    "    data = urllib.request.urlopen(url)\n",
    "    # summaries = \n",
    "    Bsoup = BeautifulSoup(data, 'html.parser')\n",
    "    titles,summaries =  Bsoup.find_all('title'), Bsoup.find_all('summary')\n",
    "\n",
    "    return titles, summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e88a8057-faf9-4cf8-b3dd-82feb0eb6c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "titles, summaries = download_articles_of_day(day=None, num_articles=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0244a934-60f8-48f5-b78c-b1064beb27cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trivial_words_list_default = ['and','a','the','','of','in','on','it','after','for','ever','never','since','at','to','too']\n",
    "\n",
    "def filter_out_non_trivial_words(wordlist,trivial_words_list=trivial_words_list_default):\n",
    "    '''\n",
    "    Function that removes trivial words from a list of words. \n",
    "    Input:\n",
    "    wordlist            = list of strings, may be lowercase or uppercase \n",
    "    trivial_words_list  = list of lowercase strings that should be removed from input \"wordlist\"\n",
    "    Ouput:\n",
    "    wordlist_nontrivial = list of strings where trivial words are removed.\n",
    "    '''\n",
    "    wordlist_nontrivial = []\n",
    "        \n",
    "    for i in range(len(wordlist)):\n",
    "        word =  wordlist[i]\n",
    "\n",
    "        ## check if word is a trivial word\n",
    "        ## conver input words to lowercase and remove '\\n' characters (if present)\n",
    "        if word.lower().strip('\\n') not in trivial_words_list:\n",
    "            wordlist_nontrivial.append(word.strip('\\n'))\n",
    "\n",
    "    return wordlist_nontrivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0810aa00-d6f2-4564-a2b1-6f5ca2f1f7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### For every paper, filter trivial words from the title\n",
    "\n",
    "def filter_nontrivial_words_from_papers(input_data,trivial_words_list=trivial_words_list_default):\n",
    "    \n",
    "    \"\"\"\n",
    "    A list of unsplitted titles/abstracts for every paper.\n",
    "    For each paper the title/abstract is splitted and all non-trivial words are removed.\n",
    "    Output is a list of words for every paper\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : list of of unsplitted titles/abstracts for every paper.\n",
    "    trivial_words_list : list of lowercase trivial words that should be removed \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of non-trivial words for every abstract/title of every paper.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### input data is splitted.\n",
    "    splitted_strings_list = []\n",
    "    for i in range(len(input_data)):\n",
    "        title = input_data[i]\n",
    "\n",
    "        ## skip the first element\n",
    "        if i > 0:\n",
    "            # print(title.string)\n",
    "            ## seperate string on ' ' & '\\n' characters\n",
    "            string_splitted = re.split(' ', title.string)\n",
    "            string_splitted = [ re.split('\\n', element)[0]  for element in string_splitted ]\n",
    "            # print(string_splitted)\n",
    "            splitted_strings_list.append(string_splitted)\n",
    "            \n",
    "    \n",
    "    print('------')\n",
    "    ### from this data trivial words are removed. \n",
    "    wordlist_nontrivial_paper = []\n",
    "\n",
    "    for index_paper in range(len(splitted_strings_list)):\n",
    "        wordlist            = splitted_strings_list[index_paper]\n",
    "        wordlist_nontrivial = filter_out_non_trivial_words(wordlist,trivial_words_list)\n",
    "\n",
    "        print(wordlist_nontrivial)\n",
    "        wordlist_nontrivial_paper.append(wordlist_nontrivial)\n",
    "        \n",
    "    return wordlist_nontrivial_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5eba3a93-8822-44aa-9541-537523ff7e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summaries[0]\n",
    "\n",
    "# # print(summaries[0].string)\n",
    "# print(re.split(' ', summaries[0].string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "de07f7a6-7f11-4d73-b577-a91d7e0af08f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "['Asymmetric', 'Thermal', 'Relaxation', 'Driven', 'Systems:', 'Rotations', 'Opposite', 'Ways']\n",
      "['Josephson-like', 'tunnel', 'resonance', 'large', 'Coulomb', 'drag', 'GaAs-based', 'electron-hole', 'bilayers']\n",
      "['Addressing', 'self-interaction', 'ELDER', 'dark', 'matter', 'from', '21-cm', 'signal']\n",
      "['$f(\\\\mathcal{G},\\\\mathrm{\\\\textit{T}})$', 'Gravity', 'Bouncing', 'Universe', 'with', 'Cosmological', 'Parameters']\n",
      "['Chaotic', 'interactions', 'between', 'dark', 'matter', 'dark', 'energy']\n",
      "['anti-correlation', 'between', 'pericentric', 'distance', 'inner', 'dark', 'matter', 'density', 'Milky', \"Way's\", 'dwarf', 'spheroidal', 'galaxies']\n",
      "['Finite', 'Temperature', 'Dynamics', 'Spin', 'Solitons', 'with', 'Applications', 'Thermocouples', 'Refrigerators']\n",
      "['use', 'dielectric', 'elements', 'axion', 'searches', 'with', 'microwave', 'resonant', 'cavities']\n",
      "['Theoretical', 'study', 'competition', 'between', 'folding', 'contact', 'interactions', 'properties', 'polymers', 'using', 'self-avoid', 'random', 'walk', 'algorithm']\n",
      "['Anthropomorphic', 'finger', 'grasping', 'applications:', '3D', 'printed', 'endoskeleton', 'soft', 'skin']\n"
     ]
    }
   ],
   "source": [
    "title_paper_wordlist_nontrivial_paper = filter_nontrivial_words_from_papers(titles,trivial_words_list=trivial_words_list_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "651d4398-cd2c-447d-a894-5d6ce9699a06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "['Bilayers', 'consisting', 'two-dimensional', '(2D)', 'electron', 'hole', 'gases', 'separated', '10', 'thick', 'AlGaAs', 'barrier', 'formed', 'charge', 'accumulation', 'grown', 'GaAs.', 'Both', 'vertical', 'lateral', 'electric', 'transport', 'millikelvin', 'temperature', 'range.', 'conductivity', 'between', 'shows', 'sharp', 'tunnel', 'resonance', 'density', '$1.1', '\\\\cdot', '10^{10}', '\\\\text{', 'which', 'consistent', 'with', 'Josephson-like', 'enhanced', 'tunnel', 'tunnel', 'resonance', 'disappears', 'with', 'increasing', 'densities', '2D', 'charge', 'gases', 'start', 'show', '2D-Fermi-gas', 'behavior.', 'Interlayer', 'persist', 'causing', 'positive', 'drag', 'voltage', 'very', 'large', 'densities.', 'transition', 'from', 'Josephson-like', 'tunnel', 'resonance', 'behavior', 'interpreted', 'phase', 'transition', 'from', 'an', 'exciton', 'gas', 'Bose-Einstein-condensate', 'state', 'degenerate', 'electron-hole', 'Fermi', 'gas.']\n",
      "['self-interacting', 'dark', 'matter', 'affect', 'various', 'cosmological', 'processes.', 'interactions', 'number', 'conserving', '(\\\\emph{e.g.}', '$2', '\\\\rightarrow', '2$)', 'or', 'violating', '(\\\\emph{e.g.}', '$3', '\\\\rightarrow', '2,\\\\,4', '\\\\rightarrow', '2$', 'etc.).', 'processes', 'where', 'three', '(or', 'more)', 'dark', 'matter', 'particles', 'undergo', 'produce', 'less', 'number', 'dark', 'matter', 'termed', 'process.', 'this', 'work,', 'self-interaction', 'dark', 'matter', 'strength', 'such', 'interactions', 'investigated', 'light', 'experimental', 'global', '21-cm', 'spectrum', 'neural', 'hydrogen', 'from', 'era', 'cosmic', 'From', 'present', 'work,', 'appears', '$2\\\\rightarrow', '2$', 'process', 'much', 'dominant', 'over', '$3\\\\rightarrow', '2$', 'process.', 'also', 'found', 'such', 'affect', 'dark', 'matter-baryon', 'elastic', 'scattering', 'cross-section.', 'study', 'also', 'indicates', 'presence', 'multi', 'component', 'dark', 'matter', 'mass', 'range', 'Universe.']\n",
      "['recent', 'few', 'years,', 'Gauss-Bonnet', '$f(\\\\mathcal{G},\\\\mathrm{\\\\textit{T}})$', 'gravity', 'has', 'fascinated', 'considerable', 'researchers', 'owing', 'its', 'coupling', 'trace', 'stress-energy', 'tensor', '$T$', 'with', 'Gauss-Bonnet', 'term', 'this', 'context,', 'focuss', 'ourselves', 'study', 'bouncing', 'universe', '$f(\\\\mathcal{G},\\\\mathrm{\\\\textit{T}})$', 'gravity', 'background.', 'Some', 'important', 'presented', 'along', 'with', 'discussion', 'cosmological', 'develop', 'minimal', 'background', 'about', 'theory', 'gravity.', 'exact', 'bouncing', 'with', 'physical', 'analysis', 'provided', 'with', 'choice', 'two', 'equation', 'state', 'parameters.', 'shown', 'results', 'do', 'agree', 'with', 'present', 'deceleration,', 'jerk', 'snap', 'parameters.', 'Moreover,', 'concluded', 'model', 'parameters', 'quite', 'important', 'validity', 'conservation', '(as', 'matter', 'coupled', 'theories', 'do', 'obey', 'usual', 'conservation']\n",
      "['this', 'study,', 'consider', 'dark', 'matter', 'dark', 'energy', 'grand-canonical', 'which', 'open,', 'non-equilibrium', 'coupled,', 'interacting', 'systems.', 'first', 'time,', 'propose', 'new', 'more', 'realistic', 'interaction', 'schema', 'explain', 'between', 'coupled', 'interacting', 'thermodynamic', 'systems.', 'Based', 'this', 'new', 'schema,', 'propose', 'new', 'theorems', 'define', 'interactions.', 'theorems', 'based', 'energy', 'conservation', 'law', 'thermodynamics.', 'obtain', 'new', 'coupled', 'equations', 'using', 'theorems.', 'numerically', 'interaction', 'equations', 'obtained', 'phase', 'space', 'diagrams', 'Lyapunov', 'show', 'interaction', 'between', 'dark', 'matter', 'dark', 'energy', 'conclude', 'these', 'theorems', 'results', 'generalized', 'all', 'interacting', 'non-equilibrium', 'systems.', 'Finally,', 'give', 'new', 'definition', 'chaos.']\n",
      "['An', 'anti-correlation', 'between', 'central', 'density', 'dark', 'matter', 'halo', '{\\\\rm', 'DM}}$)', 'pericentric', 'distances', '($r_{p}$)', 'Milky', \"(MW's)\", 'dwarf', 'spheroidal', 'galaxies', '(dSphs)', 'has', 'been', 'reported', 'existence', 'origin', 'such', 'anti-correlation', 'however', 'one', 'possibility', 'being', 'only', 'densest', 'dSphs', 'survive', 'tidal', 'field', 'towards', 'centre', 'our', 'Galaxy.', 'this', 'work,', 'place', 'emphasis', 'quantifying', 'statistical', 'significance', 'such', 'using', 'available', 'literature', 'data', 'order', 'explore', 'its', 'under', 'different', 'assumptions', 'MW', 'gravitational', 'potential,', 'various', 'derivations', '$\\\\rho_{150}$', '$r_{p}$.', 'consider', 'models', 'MW', 'isolated', 'has', 'low', '($8.8\\\\times10^{11}\\\\,M_{\\\\odot}$)', 'high', 'M_{\\\\odot}$)', 'halo', 'mass,', 'respectively,', 'well', 'which', \"MW's\", 'potential', 'perturbed', 'Large', 'Magellanic', '(LMC)', 'infall.', 'find', 'that,', 'while', 'data', 'generally', 'support', 'models', 'which', \"dSphs'\", 'central', 'DM', 'density', 'decreases', 'function', 'their', 'pericentric', 'this', 'anti-correlation', 'statistically', 'significant', '$3\\\\sigma$', 'level', '$\\\\sim$12$\\\\%$', 'combinations', '$\\\\rho_{150}$', '$r_{p}$', 'explored.', 'including', 'impact', \"LMC's\", 'infall', 'onto', 'MW', 'weakens', 'or', 'even', 'away', 'this', 'anti-correlation,', 'with', 'respect', 'models', 'which', 'MW', 'Our', 'results', 'suggest', 'strength', 'existence', 'such', 'still', 'debatable:', 'exploring', 'with', 'high-resolution', 'including', 'baryonic', 'physics', 'different', 'DM', 'flavours', 'will', 'help', 'us', 'understand', 'its', 'emergence.']\n",
      "['exploitation', 'spin', 'Berry', 'phases', 'generate', 'emergent', 'fields', 'miniaturized', 'high-quality', 'inductors', 'has', 'enjoyed', 'considerable', 'among', 'proponents', 'quantum', 'technologies', '[Nature', '586,', '202', '(2020)}].', 'this', 'breakthrough,', 'extend', 'its', 'mechanism', 'spin', 'thermoelectrics', 'probing', 'responses', 'ferrimagnetic', 'domain', 'walls', '(DWs)', 'thermal', 'gradients.', 'voltages', 'here', 'stem', 'from', 'DW-spin', 'collective', 'motion,', 'contrast', 'electron', 'transport', 'phenomena.', 'further', 'develop', 'finite-temperature', 'investigate', 'thermoelectric', 'figures', 'merit', 'attribute', 'quantum', 'superiority', 'ultrafast', 'spin', 'evolution', 'ferrimagnetism', 'tunable', 'non-Abelian', 'phases.', 'propose', 'more', 'likely', 'cause', 'DW', 'motion', 'hot', 'or', 'cold', 'regions', '(contrary', 'conclusions', 'previous', 'reports)', 'existence', 'efficient', 'magnon-momentum', 'transfers.', 'These', 'findings', 'deepen', 'understanding', 'heat-driven', 'DW', 'kinetics', 'suggest', 'profitable', 'new', 'an', 'emerging', 'realm', 'spincaloritronics.']\n",
      "['This', 'study', 'explores', 'primary', 'effects', 'dielectric', 'materials', 'resonant', 'search', 'axion', 'dark', 'matter.', 'While', 'dielectrics', 'prove', 'beneficial', 'numerous', 'cases,', 'their', 'incorporation', 'may', 'lead', 'less-than-optimal', 'especially', 'lowest', 'TM', 'mode.', 'Additionally,', 'stronger', 'electric', 'field', 'inside', 'dielectrics', 'exacerbate', 'mode', 'particular', 'higher-order', 'modes.', 'Case', 'studies', 'have', 'been', 'carried', 'using', 'combination', 'analytical', 'solutions', 'numerical', 'simulations.', 'indicate', 'dielectric', 'cavities', 'employing', '$\\\\text{TM}_{010}$', 'mode', 'significant', 'reduction', 'sensitivity', 'when', 'compared', 'similar', 'conducted', 'cavity', 'equivalent', 'frequency', 'using', 'no', 'dielectrics.']\n",
      "['self-avoid', 'random', 'walk', 'algorithm', 'has', 'been', 'extensively', 'used', 'study', 'polymers.', 'this', 'work', 'study', 'basic', 'properties', 'trajectories', 'with', 'this', 'algorithm', 'when', 'two', 'interactions', 'added', 'it:', 'contact', 'folding', 'interaction.', 'These', 'interactions', 'represent', 'internal', 'forces', 'polymer', 'well', 'effect', 'solvent.', 'When', 'independently', 'added', 'algorithm,', 'contact', 'interaction', 'creates', 'compact', 'phase', 'while', 'one', 'creates', 'extended', 'phase.', 'These', 'consequences', 'event', 'each', 'interaction.', 'other', 'hand,', 'when', 'this', 'typical', 'event', 'avoided', 'there', 'no', 'established', 'phase', 'system.', 'When', 'simultaneously', 'there', 'competition', 'between', 'interactions', 'folding', 'one', 'over', 'contact', 'one.', 'resulting', 'phase', 'always', 'extended', 'one', 'without', 'contact', 'interaction.']\n",
      "['Application', 'soft', 'compliant', 'joints', 'grasping', 'mechanisms', 'received', 'an', 'attention', 'during', 'recent', 'years.', 'This', 'article', 'suggests', 'design', 'novel', 'bio-inspired', 'compliant', 'finger', 'which', 'composed', '3D', 'rigid', 'endoskeleton', 'covered', 'soft', 'matter.', 'overall', 'integrated', 'resembles', 'biological', 'structure', 'which', 'finger', 'presents', 'an', 'look.', 'mechanical', 'properties', 'such', 'structure', 'enhanced', 'optimization', 'repetitive', 'geometrical', 'structures', 'constructs', 'bearing', 'joint', 'fingers.', 'endoskeleton', 'formed', 'manufacturing', 'such', 'geometries', 'with', 'rigid', 'materials.', 'geometry', 'endoskeleton', 'was', 'studied', 'finite', 'element', 'analysis', '(FEA)', 'obtain', 'properties:', 'high', 'stiffness', 'against', 'lateral', 'deflection', 'twisting,', 'stiffness', 'desired', 'bending', 'axis', 'fingers.', 'Results', 'validated', 'experimental', 'analysis.']\n"
     ]
    }
   ],
   "source": [
    "trivial_words_list_default = ['and','by','a','the','',  '','of','in','on','it','after',\n",
    "                              'for','ever','never','since','at','to','too','e.g.','are',\n",
    "                              'nm','is','as','we','i','go','not','can','be','that']\n",
    "\n",
    "summaries_papers_wordlist_nontrivial = filter_nontrivial_words_from_papers(summaries,trivial_words_list=trivial_words_list_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a51e2-3d76-412d-bbd3-cf1a6a7abfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
