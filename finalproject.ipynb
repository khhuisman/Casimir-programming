{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d507d25-5c7a-41d3-9ec5-e82b8bdcaf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib, urllib.request\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime\n",
    "import os\n",
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d9d909c-4b62-4ff3-bcde-918f954d1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "trivial_words_list_default = ['and','a','the','','of','in','on','it','after','for','ever','never','since','at','to','too'\n",
    "                              , 'We', 'show', 'that', 'this', 'with', 'by', 'from', 'as', 'be', 'are', 'have', 'has', 'can', \n",
    "                              'could', 'will', 'would', 'may', 'might', 'must', 'shall', 'should', 'do', 'such', 'both', 'assume'\n",
    "                              'also', 'an', 'any', 'each', 'every', 'either', 'neither', 'other', 'another', 'such', 'same', 'several',\n",
    "                              'variable', 'various', 'well', 'where', 'which', 'while', 'wide', 'within', 'yet', 'you', 'your', 'yours', 'yourself', \n",
    "                              'but', 'been']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8eec99-aa0c-403e-8af2-13ff7d89d130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_articles_of_day(day=None, num_articles=10):\n",
    "    \"\"\"\n",
    "    Downloads the titles and summaries of a given date in the condensed matter category. \n",
    "    If no inputs are given, it will do today's date and 10 articles\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    day : date.time format\n",
    "        A given date\n",
    "    num_articles : int\n",
    "                    The number of articles requested\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    titles : bs4 ResultSet\n",
    "            Contains all titles requested, can be indexed with []\n",
    "    summaries : bs4 ResultSet\n",
    "                Contains all abstracts belonging to the titles. \n",
    "\n",
    "    \"\"\"\n",
    "    if day == None:\n",
    "        day = date.today()\n",
    "\n",
    "    tomorrow = day+datetime.timedelta(days=1)\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:condensed%20matter&submittedDate:[{day}+TO+{tomorrow}]&start=0&max_results={num_articles}&sortBy=submittedDate&sortOrder=descending'\n",
    "    data = urllib.request.urlopen(url)\n",
    "    Bsoup = BeautifulSoup(data, 'html.parser')\n",
    "    titles, summaries, ids = Bsoup.find_all(\n",
    "        'title'), Bsoup.find_all('summary'), Bsoup.find_all('id')\n",
    "\n",
    "    return titles, summaries, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56350a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_subset_of_articles(todays_articles, num_articles_to_show=4, only_title=True):\n",
    "    \"\"\"\n",
    "    Shows a subset of the articles and asks the user if they are interesting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    todays_articles : tuple\n",
    "        A tuple of the form (titles, summaries, ids)\n",
    "\n",
    "    num_articles_to_show : int, optional\n",
    "        The number of articles to show. The default is 4.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    interesting_articles : list\n",
    "        A list of the indices of the interesting articles.\n",
    "    \"\"\"\n",
    "\n",
    "    titles, summaries, _ = todays_articles\n",
    "    interesting_articles = []\n",
    "\n",
    "    for i in range(num_articles_to_show):\n",
    "        print(f'Aritlce Number {i}')\n",
    "        print(titles[i+1].text)\n",
    "        if only_title == False:\n",
    "            print(summaries[i].text)\n",
    "        print()\n",
    "        while True:\n",
    "            answer = input(\"Is this article interesting? (yes/no/stop): \")\n",
    "            if answer == 'yes':\n",
    "                interesting_articles.append(i)\n",
    "                break\n",
    "            elif answer == 'no':\n",
    "                break\n",
    "            elif answer == 'stop':\n",
    "                return interesting_articles\n",
    "            else:\n",
    "                print(\"Please enter yes, no, or stop\")\n",
    "\n",
    "    return interesting_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a614b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_out_non_trivial_words(wordlist, trivial_words_list=trivial_words_list_default):\n",
    "    \"\"\"\n",
    "    Function that removes trivial words from a list of words. \n",
    "    Parameters\n",
    "    ----------\n",
    "    wordlist : list of strings\n",
    "                , may be lowercase or uppercase \n",
    "    trivial_words_list : list of lowercase strings \n",
    "                        that should be removed from input \"wordlist\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    wordlist_nontrivial : list of strings \n",
    "                        where trivial words are removed.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    wordlist_nontrivial = []\n",
    "\n",
    "    for i in range(len(wordlist)):\n",
    "        word = wordlist[i]\n",
    "        # conver input words to lowercase and remove '\\n' characters (if present)\n",
    "        if word.lower().strip('\\n').strip(',').strip('.') not in trivial_words_list:\n",
    "            wordlist_nontrivial.append(word.strip('\\n').strip(',').strip('.'))\n",
    "\n",
    "    return wordlist_nontrivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da798c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def most_likely_interesting_articles(\n",
    "    info, interesting_indices, shown_upto, trivial_words_list\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    info : tuple\n",
    "        Tuple containing titles, summaries, and ids of articles\n",
    "    interesting_indices : list\n",
    "        List of indices of interesting articles\n",
    "    shown_upto : int\n",
    "        Number of articles shown so far\n",
    "    trivial_words_list : list\n",
    "        List of trivial words to be removed from articles\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    comparison_percentages : list\n",
    "        List of percentages of interesting words in each article\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Define percentage as how many words of an article appear in the interesting\n",
    "    articles list divided by total number of words in the article.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(interesting_indices) > 0, \"The interesting articles must be more than 0\"\n",
    "\n",
    "    titles, summaries, _ = info\n",
    "    interesting_wordlist = []\n",
    "    for i in interesting_indices:\n",
    "        interesting_wordlist += titles[i + 1].text.split()\n",
    "        interesting_wordlist += summaries[i].text.split()\n",
    "\n",
    "    interesting_wordlist_nontrivial = filter_out_non_trivial_words(\n",
    "        interesting_wordlist, trivial_words_list\n",
    "    )\n",
    "\n",
    "    unique_words = np.unique(interesting_wordlist_nontrivial)\n",
    "\n",
    "    comparison_percentages = []\n",
    "    for i in range(len(summaries) - shown_upto):\n",
    "        wordlist = summaries[i + shown_upto].text.split()\n",
    "        wordlist_nontrivial = filter_out_non_trivial_words(wordlist, trivial_words_list)\n",
    "        interesting_words = len(\n",
    "            np.nonzero(np.isin(wordlist_nontrivial, unique_words))[0]\n",
    "        )\n",
    "        comparison_percentages.append(interesting_words / len(wordlist_nontrivial))\n",
    "\n",
    "    print(\"The next most likely interesting article is:\")\n",
    "    print()\n",
    "    print(titles[np.argmax(comparison_percentages) + shown_upto + 1].text)\n",
    "    print(summaries[np.argmax(comparison_percentages) + shown_upto].text)\n",
    "    print(f\"With an overlap in words of {np.max(comparison_percentages)*100:.2f}%\")\n",
    "    return np.argmax(comparison_percentages) + shown_upto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45be47e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d904d4df-60f3-4f24-ab08-4f5d6fb93577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_arxivID_of_papers(ids):\n",
    "    \"\"\"\n",
    "    A list of internet links including the ArXiv ids is converted to a list with only the arxiv ids.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ids : list of internet links including the ArXiv ids for every paper.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of ArXiv ids according to the format: \"YYMM.NNNNNv{versionumber}\" for every abstract/title of every paper. YY = year, MM = month. NNNNN = som identifier number \n",
    "\n",
    "    \"\"\"\n",
    "    idlist_total = []\n",
    "    for i in range(len(ids)):\n",
    "        id1 = ids[i]\n",
    "        if i > 0:\n",
    "            string_seperated = re.split('/', id1.string)\n",
    "            idlist_pdf = string_seperated[4]\n",
    "            # ArXiv id is given by: YYMM.NNNNNv1 therefore when seperate it should have length 14.\n",
    "            # See: https://info.arxiv.org/help/arxiv_identifier.html#new\n",
    "            numberlist = re.split('', idlist_pdf)\n",
    "            assert len(\n",
    "                numberlist) == 14, 'This is not the ArXiv id, pdf file cannot be saved'\n",
    "            idlist_total.append(idlist_pdf)\n",
    "\n",
    "    return idlist_total\n",
    "\n",
    "\n",
    "def save_articles_as_pdf(index_article_list,\n",
    "                         ids):\n",
    "    \"\"\"\n",
    "    Saves interesting papers  as .pdf file in the current repository.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    index_article_list : list of indices corresponding to the papers that should be saved as pdf.\n",
    "    ids         : list of internet links including the ArXiv ids for every paper.\n",
    "    save_papers : boolean, if True papers are saved. If False they are not saved.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prints article's filename of the saved papers.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    idlist_total = get_arxivID_of_papers(ids)\n",
    "\n",
    "    # Some checks\n",
    "    assert max(index_article_list) <= len(\n",
    "        ids), 'Index of paper does not exist. All indices should be smaller than {} '.format(len(ids))\n",
    "    assert min(index_article_list) >= 0, 'Negative index for paper is not allowed.'\n",
    "\n",
    "    for paper_index in index_article_list:\n",
    "        article_id = idlist_total[paper_index]\n",
    "        paper = next(arxiv.Search(id_list=[article_id]).results())\n",
    "\n",
    "        # name of file\n",
    "        filename = 'paper_' + str(paper_index) + '_' + article_id + '.pdf'\n",
    "        print(f'Downloaded paper with {filename}')\n",
    "        if os.path.isfile(filename):\n",
    "            print('File already exists')\n",
    "        else:\n",
    "            paper.download_pdf(filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "112c5ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aritlce Number 0\n",
      "Constraining the onset density for the QCD phase transition with the\n",
      "  neutrino signal from core-collapse supernovae\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Is this article interesting? (yes/no/stop):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aritlce Number 1\n",
      "Time-Asymmetric Protocol Optimization for Efficient Free Energy\n",
      "  Estimation\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Is this article interesting? (yes/no/stop):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aritlce Number 2\n",
      "Imaging 3D Chemistry at 1 nm Resolution with Fused Multi-Modal Electron\n",
      "  Tomography\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Is this article interesting? (yes/no/stop):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aritlce Number 3\n",
      "A Cookbook of Self-Supervised Learning\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Is this article interesting? (yes/no/stop):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aritlce Number 4\n",
      "Colour-Flavour Locked Quark Stars in Light of the Compact Object in HESS\n",
      "  J1731-347 and the GW190814 Event\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Is this article interesting? (yes/no/stop):  stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next most likely interesting article is:\n",
      "\n",
      "Reconstruction of an Observationally Constrained $f(R, T)$ gravity model\n",
      "  In this paper, an attempt is made to construct a\n",
      "Friedmann-Lemaitre-Robertson-Walker model in $f(R,T)$ gravity with a perfect\n",
      "fluid that yields acceleration at late times. We take $f(R,T)$ as $R$ + $8\\pi\n",
      "\\mu T$. As in the $\\Lambda$CDM model, we take the matter to consist of two\n",
      "components, viz., $\\Omega_m$ and $\\Omega_{\\mu}$ such that $\\Omega_m$ +\n",
      "$\\Omega_{\\mu}$=1. The parameter $\\Omega_m$ is the matter density (baryons +\n",
      "dark matter), and $\\Omega_{\\mu}$ is the density associated with the Ricci\n",
      "scalar $R$ and the trace $T$ of the energy momentum tensor, which we shall call\n",
      "dominant matter. We find that at present $\\Omega_{\\mu}$ is dominant over\n",
      "$\\Omega_m$, and that the two are in the ratio 3:1 to 3:2 according to the three\n",
      "data sets: (i) 77 Hubble OHD data set (ii) 580 SNIa supernova distance modulus\n",
      "data set and (iii) 66 pantheon SNIa data which include high red shift data in\n",
      "the range $0\\leq z\\leq 2.36$. We have also calculated the pressures and\n",
      "densities associated with the two matter densities, viz., $p_{\\mu}$,\n",
      "$\\rho_{\\mu}$, $p_m$ and $\\rho_m$, respectively. It is also found that at\n",
      "present, $\\rho_{\\mu}$ is greater than $\\rho_m$. The negative dominant matter\n",
      "pressure $p_{\\mu}$ creates acceleration in the universe. Our deceleration and\n",
      "snap parameters show a change from negative to positive, whereas the jerk\n",
      "parameter is always positive. This means that the universe is at present\n",
      "accelerating and in the past it was decelerating. State finder diagnostics\n",
      "indicate that our model is at present a dark energy quintessence model. The\n",
      "various other physical and geometric properties of the model are also\n",
      "discussed.\n",
      "\n",
      "With an overlap in words of 27.12%\n",
      "Downloaded paper with paper_35_2304.11616v1.pdf\n",
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "#Main loop example:\n",
    "info = download_articles_of_day(day=None, num_articles=50)\n",
    "intreseting = show_subset_of_articles(info, num_articles_to_show=8, only_title=True)\n",
    "interesting_article_index = most_likely_interesting_articles(info, intreseting, 8, trivial_words_list_default)\n",
    "titles, summaries, ids = info\n",
    "save_articles_as_pdf([interesting_article_index], ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade671f9-7ae9-42fc-9494-fdb37fbce3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
