{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2b5ed144-aadd-4a9c-a195-91b36e1ac9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## “Thank you to arXiv for use of its open access interoperability.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d507d25-5c7a-41d3-9ec5-e82b8bdcaf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib, urllib.request\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da32b16-0638-4000-b1d8-4328153cff80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arxiv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m### To install: open terminal and run: \"pip install arxiv\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m## For saving paper's pdfs\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39marxiv\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'arxiv'"
     ]
    }
   ],
   "source": [
    "### To install: open terminal and run: \"pip install arxiv\"\n",
    "## For saving paper's pdfs\n",
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2e72f9-2d1b-4e1c-b25b-41dc59c9b72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paper = next(arxiv.Search(id_list=[\"1605.08386v1\"]).results())\n",
    "# paper.download_pdf(filename=\"downloaded-paper.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8eec99-aa0c-403e-8af2-13ff7d89d130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_articles_of_day(day=None, num_articles=10):\n",
    "    \"\"\"\n",
    "    Downloads the titles and summaries of a given date in the condensed matter category. \n",
    "    If no inputs are given, it will do today's date and 10 articles\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    day : date.time format\n",
    "        A given date\n",
    "    num_articles : int\n",
    "                    The number of articles requested\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    titles : bs4 ResultSet\n",
    "            Contains all titles requested, can be indexed with []\n",
    "    summaries : bs4 ResultSet\n",
    "                Contains all abstracts belonging to the titles. \n",
    "    \n",
    "    \"\"\"\n",
    "    if day==None:\n",
    "        day = date.today()\n",
    "\n",
    "    tomorrow=day+datetime.timedelta(days=1)\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:condensed%20matter&submittedDate:[{day}+TO+{tomorrow}]&start=0&max_results={num_articles}&sortBy=submittedDate&sortOrder=descending'\n",
    "    data = urllib.request.urlopen(url)\n",
    "    Bsoup = BeautifulSoup(data, 'html.parser')\n",
    "    titles,summaries,ids =  Bsoup.find_all('title'), Bsoup.find_all('summary'),Bsoup.find_all('id')\n",
    "\n",
    "    return titles, summaries,ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88a8057-faf9-4cf8-b3dd-82feb0eb6c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rzijderveld/Library/Python/3.9/lib/python/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "titles, summaries,ids = download_articles_of_day(day=None, num_articles=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e1ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = download_articles_of_day(day=None, num_articles=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56350a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_subset_of_articles(todays_articles, num_articles_to_show=4):\n",
    "    \n",
    "    titles, summaries, _ = todays_articles\n",
    "    interesting_articles = []\n",
    "    \n",
    "    for i in range(num_articles_to_show): \n",
    "        print(f'Aritlce Number {i}')\n",
    "        print(titles[i+1].text)\n",
    "        print(summaries[i].text)\n",
    "        print()\n",
    "        while True:\n",
    "            answer = input(\"Is this article interesting? (yes/no/stop): \")\n",
    "            if answer == 'yes':\n",
    "                interesting_articles.append(i)\n",
    "                break\n",
    "            elif answer == 'no':\n",
    "                break\n",
    "            elif answer == 'stop':\n",
    "                return interesting_articles\n",
    "            else:\n",
    "                print(\"Please enter yes, no, or stop\")\n",
    "        \n",
    "    return interesting_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bbb98fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aritlce Number 0\n",
      "Universal scaling function ansatz for finite-temperature jamming\n",
      "  We cast a nonzero-temperature analysis of the jamming transition into the\n",
      "framework of a scaling ansatz. We show that four distinct regimes for scaling\n",
      "exponents of thermodynamic derivatives of the free energy such as pressure,\n",
      "bulk and shear moduli, can be consolidated by introducing a universal scaling\n",
      "function with two branches. Both the original analysis and the scaling theory\n",
      "assume that the system always resides in a single basis in the energy\n",
      "landscape. The two branches are separated by a line $T^*(\\Delta \\phi)$ in the\n",
      "$T-\\Delta \\phi$ plane, where $\\Delta \\phi=\\phi-\\phi_c^\\Lambda$ is the deviation\n",
      "of the packing fraction from its critical, jamming value, $\\phi_c^\\Lambda$, for\n",
      "that basin. The branch for $T<T^*(\\Delta \\phi)$ reduces at $T=0$ to an earlier\n",
      "scaling ansatz that is restricted to $T=0$, $\\Delta \\phi \\ge 0$, while the\n",
      "branch for $T>T^*(\\Delta \\phi)$ reproduces exponents observed for thermal hard\n",
      "spheres. In contrast to the usual scenario for critical phenomena, the two\n",
      "branches are characterized by different exponents. We suggest that this unusual\n",
      "feature can be resolved by the existence of a dangerous irrelevant variable\n",
      "$u$, which can appear to modify exponents if the leading $u=0$ term is\n",
      "sufficiently small in the regime described by one of the two branches of the\n",
      "scaling function.\n",
      "\n",
      "\n",
      "Aritlce Number 1\n",
      "Distance-dependent emission spectrum from two qubits in a\n",
      "  strong-coupling regime\n",
      "  We study the emission spectrum of two distant qubits strongly coupled to a\n",
      "waveguide by using the numerical and analytical approaches, which are beyond\n",
      "the Markovian approximation and the rotating-wave approximation (RWA). The\n",
      "numerical approach combines the Dirac-Frenkel time-dependent variational\n",
      "principle with the multiple Davydov $D_{1}$ ansatz. A transformed RWA (TRWA)\n",
      "treatment and a standard perturbation (SP) are used to analytically calculate\n",
      "the emission spectrum. It is found that the variational approach and the TRWA\n",
      "treatment yield accurate emission spectra of the two distant qubits in certain\n",
      "strong coupling regimes while the SP breaks down. The emission spectrum is\n",
      "found to be asymmetric irrespective of the two-qubit distance and exhibits a\n",
      "single peak, doublet, and multipeaks depending on the two-qubit distance as\n",
      "well as the initial states. In sharply contrast with the single-qubit case, the\n",
      "excited-state populations of the two qubits can ultraslowly decay due to the\n",
      "subradiance even in the presence of a strong qubit-waveguide coupling, which in\n",
      "turn yields ultranarrow emission line. Our results provide insights into the\n",
      "emission spectral features of the two distant qubits in the strong light-matter\n",
      "coupling regime.\n",
      "\n",
      "\n",
      "Aritlce Number 2\n",
      "Jamming, relaxation, and memory in a structureless glass former\n",
      "  Real structural glasses form through various out-of-equilibrium processes,\n",
      "including temperature quenches, rapid compression, shear, and aging. Each of\n",
      "these processes should be formally understandable within the recently\n",
      "formulated dynamical mean-field theory of glasses, but many of the numerical\n",
      "tools needed to solve the relevant equations for sufficiently long timescales\n",
      "do not yet exist. Numerical simulations of structureless (and therefore\n",
      "mean-field-like) model glass formers can nevertheless aid searching for and\n",
      "understanding such solutions, thanks to their ability to disentangle structural\n",
      "from dimensional effects. We here study the infinite-range Mari-Kurchan model\n",
      "under simple non-equilibrium processes and compare the results with those from\n",
      "the random Lorentz gas [J. Phys. A: Math. Theor. 55 334001, (2022)], which are\n",
      "both mean-field-like and become formally equivalent in the limit of infinite\n",
      "spatial dimensions. Of particular interest are jamming from crunching and under\n",
      "instantaneous temperature quenches. The study allows for an algorithmic\n",
      "understanding of the jamming density and of its approach to the\n",
      "infinite-dimensional limit. The results provide important insight into the\n",
      "eventual solution of the dynamical mean-field theory, including onsets and\n",
      "anomalous relaxation, as well as into the various algorithmic schemes for\n",
      "jamming.\n",
      "\n",
      "\n",
      "Aritlce Number 3\n",
      "Attractor Solutions in Interacting Dark Energy Models\n",
      "  We investigate a cosmological model in which dark energy, represented by a\n",
      "quintessential scalar field, is coupled to a dark-matter perfect fluid in the\n",
      "spatially flat Friedmann-Robertson-Walker Universe. This allows an energy\n",
      "exchange in the dark sector which could happen both at early times before\n",
      "recombination era or at late times. We use the coupling function\n",
      "$Q=\\gamma\\rho_{dm}\\dot{\\varphi}$ which is induced by conformal transforming\n",
      "scalar-tensor and $f(R)$ gravity theories to Einstein frame. It is argued that\n",
      "there is a connection between this coupling function and $Q\\propto \\rho_{dm}H$.\n",
      "A dynamical analysis is used to show that there are early- and late-time\n",
      "attracting solutions for which the system evolves for a wide range of initial\n",
      "conditions. These attractors generalize the scaling solutions which have been\n",
      "already found in the non-interacting case.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intreseting = show_subset_of_articles(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bdbff3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(intreseting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da798c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0244a934-60f8-48f5-b78c-b1064beb27cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trivial_words_list_default = ['and','a','the','','of','in','on','it','after','for','ever','never','since','at','to','too']\n",
    "\n",
    "def filter_out_non_trivial_words(wordlist,trivial_words_list=trivial_words_list_default):\n",
    "    '''\n",
    "    Function that removes trivial words from a list of words. \n",
    "    Input:\n",
    "    wordlist            = list of strings, may be lowercase or uppercase \n",
    "    trivial_words_list  = list of lowercase strings that should be removed from input \"wordlist\"\n",
    "    Ouput:\n",
    "    wordlist_nontrivial = list of strings where trivial words are removed.\n",
    "    '''\n",
    "    wordlist_nontrivial = []\n",
    "        \n",
    "    for i in range(len(wordlist)):\n",
    "        word =  wordlist[i]\n",
    "\n",
    "        ## check if word is a trivial word\n",
    "        ## conver input words to lowercase and remove '\\n' characters (if present)\n",
    "        if word.lower().strip('\\n') not in trivial_words_list:\n",
    "            wordlist_nontrivial.append(word.strip('\\n'))\n",
    "\n",
    "    return wordlist_nontrivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0810aa00-d6f2-4564-a2b1-6f5ca2f1f7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### For every paper, filter trivial words from the title\n",
    "\n",
    "def filter_nontrivial_words_from_papers(input_data,trivial_words_list=trivial_words_list_default):\n",
    "    \n",
    "    \"\"\"\n",
    "    A list of unsplitted titles/abstracts for every paper.\n",
    "    For each paper the title/abstract is splitted and all non-trivial words are removed.\n",
    "    Output is a list of words for every paper\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : list of of unsplitted titles/abstracts for every paper.\n",
    "    trivial_words_list : list of lowercase trivial words that should be removed \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of non-trivial words for every abstract/title of every paper.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### input data is splitted.\n",
    "    splitted_strings_list = []\n",
    "    for i in range(len(input_data)):\n",
    "        title = input_data[i]\n",
    "\n",
    "        ## skip the first element\n",
    "        if i > 0:\n",
    "            # print(title.string)\n",
    "            ## seperate string on ' ' & '\\n' characters\n",
    "            string_splitted = re.split(' ', title.string)\n",
    "            string_splitted = [ re.split('\\n', element)[0]  for element in string_splitted ]\n",
    "            # print(string_splitted)\n",
    "            splitted_strings_list.append(string_splitted)\n",
    "            \n",
    "    \n",
    "    print('------')\n",
    "    ### from this data trivial words are removed. \n",
    "    wordlist_nontrivial_paper = []\n",
    "\n",
    "    for index_paper in range(len(splitted_strings_list)):\n",
    "        wordlist            = splitted_strings_list[index_paper]\n",
    "        wordlist_nontrivial = filter_out_non_trivial_words(wordlist,trivial_words_list)\n",
    "\n",
    "        print(wordlist_nontrivial)\n",
    "        wordlist_nontrivial_paper.append(wordlist_nontrivial)\n",
    "        \n",
    "    return wordlist_nontrivial_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d904d4df-60f3-4f24-ab08-4f5d6fb93577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_arxivID_of_papers(ids):\n",
    "    \n",
    "    \"\"\"\n",
    "    A list of internet links including the ArXiv ids is converted to a list with only the arxiv ids.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ids : list of internet links including the ArXiv ids for every paper.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of ArXiv ids according to the format: \"YYMM.NNNNNv{versionumber}\" for every abstract/title of every paper. YY = year, MM = month. NNNNN = som identifier number \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    idlist_total = []\n",
    "    for i in range(len(ids)):\n",
    "            id1 = ids[i]\n",
    "\n",
    "            ## skip the first element\n",
    "            if i > 0:\n",
    "                # print(id1.string)\n",
    "                ## seperate string on '/' characters\n",
    "                string_seperated = re.split('/', id1.string)\n",
    "                idlist_pdf = idlist_converted[4]\n",
    "                # print(idlist_pdf)\n",
    "\n",
    "                #### ArXiv id is given by: YYMM.NNNNNv1 therefore when seperate it should have length 14.\n",
    "                ### See: https://info.arxiv.org/help/arxiv_identifier.html#new\n",
    "                numberlist = re.split('',idlist_pdf)\n",
    "                assert len(numberlist) == 14, 'This is not the ArXiv id, pdf file cannot be saved'\n",
    "\n",
    "                idlist_total.append(idlist_pdf)\n",
    "\n",
    "                # year_index  = 10*int(numberlist[1]) + int(numberlist[2])\n",
    "                # month_index = 10*int(numberlist[3]) + int(numberlist[4])\n",
    "                \n",
    "                \n",
    "    return idlist_total\n",
    "\n",
    "\n",
    "def save_articles_as_pdf(index_article_list,\n",
    "                         ids,save_papers=\n",
    "                        False):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Saves interesting papers  as .pdf file in the current repository.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index_article_list : list of indices corresponding to the papers that should be saved as pdf.\n",
    "    ids         : list of internet links including the ArXiv ids for every paper.\n",
    "    save_papers : boolean, if True papers are saved. If False they are not saved.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    prints article's filename of the saved papers.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    idlist_total = get_arxivID_of_papers(ids)\n",
    "    \n",
    "    ## Some checks\n",
    "    assert max(index_article_list) <= len(ids), 'Index of paper does not exist. All indices should be smaller than {} '.format(len(ids))\n",
    "    assert min(index_article_list) >= 0, 'Negative index for paper is not allowed.'\n",
    "    \n",
    "    for paper_index in index_article_list:\n",
    "        article_id  = idlist_total[paper_index]\n",
    "        paper = next(arxiv.Search(id_list=[article_id]).results())\n",
    "        \n",
    "        ## name of file\n",
    "        filename = 'paper_' + str(paper_index) + '_' + article_id + '.pdf'\n",
    "        print(filename)\n",
    "        if save_papers == True:\n",
    "            paper.download_pdf(filename=filename)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5eba3a93-8822-44aa-9541-537523ff7e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summaries[0]\n",
    "\n",
    "# # print(summaries[0].string)\n",
    "# print(re.split(' ', summaries[0].string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de07f7a6-7f11-4d73-b577-a91d7e0af08f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "['Symmetry', 'Fractionalized', '(Irrationalized)', 'Fusion', 'Rules', 'Two', 'Domain-Wall', 'Verlinde', 'Formulae']\n",
      "['Signatures', 'Fractional', 'Quantum', 'Anomalous', 'Hall', 'States', 'Twisted', 'MoTe2', 'Bilayer']\n",
      "['Effective', 'electric', 'field:', 'quantifying', 'sensitivity', 'searches', 'new', 'P,T-odd', 'physics', 'with', 'EuCl$_3\\\\cdot$6H$_2$O']\n",
      "['Big', 'Bang', 'initial', 'conditions', 'self-interacting', 'hidden', 'dark', 'matter']\n",
      "['Multi-Purpose', 'Platform', 'Analog', 'Quantum', 'Simulation']\n",
      "['Exciton', 'band', 'structure', 'V$_2$O$_5$']\n",
      "['first', 'application', 'machine', 'deep', 'learning', 'background', 'rejection', 'ALPS', 'II', 'TES', 'detector']\n",
      "['Search', 'gravitational-lensing', 'signatures', 'full', 'third', 'observing', 'run', 'LIGO-Virgo', 'network']\n",
      "['Detached', 'Continuous', 'Circumstellar', 'Matter', 'Type', 'Ibc', 'Supernovae', 'from', 'Mass', 'Eruption']\n",
      "['NvDEx-100', 'Conceptual', 'Design', 'Report']\n"
     ]
    }
   ],
   "source": [
    "title_paper_wordlist_nontrivial_paper = filter_nontrivial_words_from_papers(titles,trivial_words_list=trivial_words_list_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "651d4398-cd2c-447d-a894-5d6ce9699a06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "['interplay', 'between', 'spontaneous', 'symmetry', 'breaking', 'topology', 'result', 'exotic', 'quantum', 'states', 'matter.', 'celebrated', 'example', 'quantum', 'Hall', '(QAH)', 'state,', 'which', 'exhibits', 'an', 'integer', 'quantum', 'Hall', 'effect', 'magnetic', 'field', 'thanks', 'its', 'intrinsic', 'ferromagnetism.', 'presence', 'electron-electron', 'interactions,', 'exotic', 'fractional-QAH', '(FQAH)', 'states', 'magnetic', 'field', 'emerge.', 'These', 'states', 'could', 'host', 'fractional', 'excitations,', 'non-Abelian', 'anyons', '-', 'crucial', 'building', 'blocks', 'topological', 'quantum', 'Flat', 'Chern', 'bands', 'widely', 'considered', 'desirable', 'venue', 'FQAH', 'state.', 'this', 'purpose,', 'twisted', 'transition', 'metal', 'homobilayers', 'rhombohedral', 'stacking', 'have', 'recently', 'been', 'promising', 'material', 'platform.', 'Here,', 'report', 'experimental', 'FQAH', 'states', '3.7-degree', 'twisted', 'MoTe2', 'bilayer.', 'Magnetic', 'dichroism', 'measurements', 'reveal', 'robust', 'ferromagnetic', 'states', 'hole', 'filled', \"moir\\\\'e\", 'minibands.', 'Using', 'trion', 'photoluminescence', 'obtain', 'Landau', 'fan', 'diagram', 'which', 'shows', 'linear', 'shifts', 'carrier', 'corresponding', 'v=-2/3', '-3/5', 'ferromagnetic', 'states', 'with', 'magnetic', 'field.', 'These', 'shifts', 'match', 'Streda', 'formula', 'dispersion', 'states', 'with', 'fractionally', 'quantized', 'Hall', 'conductance', '-2/3$e^2/h$', 'respectively.', 'Moreover,', 'v=-1', 'state', 'exhibits', 'dispersion', 'Chern', 'number', '-1,', 'consistent', 'with', 'predicted', 'QAH', 'state.', 'several', 'non-ferromagnetic', 'states', 'electron', 'doping', 'side', 'do', 'i.e.,', 'trivial', 'correlated', 'insulators.', 'observed', 'topological', 'further', 'electrically', 'driven', 'into', 'topologically', 'trivial', 'states.', 'findings', 'provide', 'clear', 'evidence', 'long-sought', 'FQAH', 'states,', 'putting', 'MoTe2', \"moir\\\\'e\", 'superlattices', 'fascinating', 'platform', 'exploring', 'excitations.']\n",
      "['Laboratory-scale', 'precision', 'experiments', 'promising', 'approach', 'searching', 'physics', 'beyond', 'standard', 'model.', 'Non-centrosymmetric', 'solids', 'offer', 'statistical', 'sensitivity', 'efforts', 'search', 'new', 'fields,', 'whose', 'violate', 'discrete', 'parity', 'time-reversal', 'symmetries.', 'One', 'electric', 'Cosmic', 'Axion', 'Spin', 'Precession', 'Experiment', '(CASPEr-e),', 'sensitive', 'defining', 'interaction', 'QCD', 'axion', 'dark', 'matter', 'gluons', 'atomic', 'nuclei.', 'effective', 'electric', 'field', 'parameter', 'quantifies', 'sensitivity', 'such', 'experiments', 'new', 'physics.', 'describe', 'theoretical', 'approach', 'calculating', 'effective', 'electric', 'field', 'sites', 'ionic', 'insulating', 'solids.', 'consider', 'specific', 'EuCl$_3\\\\cdot$6H$_2$O', 'crystal,', 'which', 'particularly', 'promising', 'optimistic', 'estimate', 'effective', 'electric', 'field', 'isotope', 'this', 'crystal', '10', 'MV/cm.', 'calculation', 'uncertainty', 'two', 'orders', 'magnitude,', 'dominated', 'evaluation', 'nuclear', 'Schiff', 'moment.']\n",
      "['variety', 'supergravity', 'string', 'models', 'involve', 'hidden', 'sectors', 'where', 'sectors', 'may', 'couple', 'feebly', 'with', 'visible', 'sectors', 'via', 'variety', 'While', 'coupling', 'hidden', 'sector', 'visible', 'sector', 'its', 'coupling', 'inflaton', 'largely', 'unknown.', 'could', 'couple', 'feebly', 'with', 'same', 'strength', 'visible', 'sector', 'which', 'would', 'result', 'either', 'or', 'hot', 'hidden', 'sector', 'end', 'reheating.', 'These', 'two', 'possibilities', 'lead', 'significantly', 'different', 'outcomes', 'observables.', 'investigate', 'thermal', 'evolution', 'two', 'sectors', 'cosmologically', 'consistent', 'hidden', 'dark', 'matter', 'model', 'where', 'hidden', 'sector', 'visible', 'sector', 'coupled', 'their', 'thermal', 'evolution', 'occurs', 'without', 'assumption', 'entropy', 'conservation', 'each', 'sector.', 'Within', 'this', 'framework', 'analyze', 'phenomena', 'illustrate', 'their', 'dependence', 'initial', 'conditions.', 'include', 'allowed', 'parameter', 'space', 'models,', 'dark', 'matter', 'relic', 'density,', 'matter', 'cross', 'section,', 'effective', 'massless', 'neutrino', 'species', 'BBN', 'self-interacting', 'dark', 'matter', 'cross-section,', 'where', 'self-interaction', 'occurs', 'exchange', 'dark', 'photon,', 'Sommerfeld', 'enhancement.', 'Finally', 'fits', 'dependence', 'dark', 'matter', 'cross', 'sections', 'from', 'galaxy', 'scales', 'galaxy', 'clusters', 'given.', 'analysis', 'indicates', 'significant', 'effects', 'initial', 'conditions', 'observables', 'listed', 'above.', 'analysis', 'out', 'within', 'framework', 'where', 'dark', 'matter', 'constituted', 'dark', 'mediation', 'between', 'visible', 'hidden', 'sector', 'occurs', 'via', 'exchange', 'dark', 'photons.', 'techniques', 'discussed', 'here', 'may', 'have', 'wider', 'class', 'hidden', 'sector', 'models', 'using', 'different', 'between', 'visible', 'hidden', 'sectors', 'explore', 'impact', 'Bang', 'initial', 'conditions', 'observable', 'physics.']\n",
      "['Atom-based', 'quantum', 'simulators', 'have', 'had', 'tremendous', 'success', 'tackling', 'quantum', 'many-body', 'problems,', 'owing', 'precise', 'dynamical', 'they', 'provide', 'over', \"systems'\", 'parameters.', 'They', 'are,', 'however,', 'optimized', 'address', 'specific', 'type', 'problems.', 'Here,', 'present', 'implementation', '$^6$Li-based', 'quantum', 'gas', 'platform', 'provides', 'capabilities', 'able', 'address', 'variety', 'quantum', 'many-body', 'Our', 'two-chamber', 'architecture', 'relies', 'robust', 'easy-to-implement', 'gray', 'molasses', 'optical', 'transport', 'from', 'laser-cooling', 'chamber', 'glass', 'cell', 'with', 'excellent', 'optical', 'access.', 'There,', 'first', 'create', 'unitary', 'superfluids', 'three-dimensional', 'axially', 'symmetric', 'harmonic', 'trap', 'them', 'using', 'situ', 'thermometry,', 'reaching', 'temperatures', 'below', '20', 'nK.', 'allows', 'us', 'enter', 'deep', 'superfluid', 'regime', 'with', 'samples', 'extreme', 'where', 'interparticle', 'spacing', 'sufficiently', 'large', 'direct', 'imaging.', 'Secondly,', 'generate', 'optical', 'lattice', 'potentials', 'with', 'honeycomb', 'geometry', 'which', 'study', 'diffraction', 'molecular', 'condensates,', 'show', 'how', 'going', 'beyond', 'Kapitza-Dirac', 'regime', 'us', 'unambiguously', 'distinguish', 'between', 'two', 'geometries.', 'With', 'probe', 'quantum', 'many-body', 'physics', 'both', 'discrete', 'continuous', 'its', 'suitability', 'bulk', 'single-atom', 'imaging,', 'our', 'setup', 'an', 'important', 'step', 'towards', 'achieving', 'wide-scope', 'quantum', 'simulator.']\n",
      "['Excitonic', 'effects', 'due', 'correlation', 'electrons', 'holes', 'excited', 'matter', 'dominate', 'optical', 'spectra', 'many', 'interesting', 'materials.', 'usually', 'studied', 'long-wavelength', 'limit.', 'Here', 'investigate', 'non-vanishing', 'momentum', 'transfer,', 'corresponding', 'shorter', 'calculate', 'exciton', 'dispersion', 'prototypical', 'layered', 'V$_2$O$_5$', 'solving', 'Bethe-Salpeter', 'equation', 'many-body', 'theory.', 'discuss', 'change', 'excitation', 'energy', 'intensity', 'function', 'wavevector', 'bright', 'dark', 'excitons,', 'respectively,', 'origin', 'excitons', 'along', 'their', 'dispersion.', 'highlight', 'role', 'electron-hole', 'exchange', 'with', 'its', 'impact', 'exciton', 'singlet-triplet', 'splitting', 'difference', 'between', 'part', 'macroscopic', 'dielectric', 'function', 'loss', 'function.']\n",
      "['Axions', 'axion-like', 'particles', 'hypothetical', 'particles', 'predicted', 'standard', 'model', 'promising', 'cold', 'dark', 'matter', 'candidates.', 'Any', 'Light', 'Particle', 'Search', '(ALPS', 'II)', 'experiment', 'experiment', 'aims', 'produce', 'these', 'particles', 'strong', 'light', 'source', 'magnetic', 'field', 'subsequently', 'detect', 'them', 'reconversion', 'into', 'photons.', 'With', 'an', 'expected', 'rate', '$\\\\sim$', '1', 'photon', 'per', 'sensitive', 'detection', 'scheme', 'needs', 'employed', 'characterized.', 'One', 'detector', 'based', 'transition', 'edge', 'sensor', '(TES).', 'Here,', 'machine', 'deep', 'learning', 'algorithms', 'rejection', 'events', 'recorded', 'with', 'TES.', 'also', 'present', 'first', 'application', 'neural', 'networks', 'classify', 'time', 'series', 'data', 'measured', 'with']\n",
      "['Gravitational', 'lensing', 'massive', 'objects', 'along', 'line', 'sight', 'causes', 'distortions', 'gravitational', 'wave-signals;', 'such', 'distortions', 'may', 'information', 'about', 'fundamental', 'physics,', 'cosmology', 'astrophysics.', 'work,', 'have', 'extended', 'search', 'lensing', 'signatures', 'all', 'binary', 'hole', 'events', 'from', 'third', 'observing', 'run', 'LIGO--Virgo', 'network.', 'repeated', 'signals', 'from', 'strong', 'lensing', '1)', 'performing', 'targeted', 'subthreshold', 'signals,', '2)', 'calculating', 'degree', 'overlap', 'amongst', 'intrinsic', 'parameters', 'sky', 'location', 'pairs', 'signals,', '3)', 'comparing', 'spectrograms', 'amongst', 'pairs', 'signals,', '4)', 'performing', 'Bayesian', 'analysis', 'takes', 'into', 'account', 'selection', 'effects', 'knowledge.', 'also', 'search', 'distortions', 'gravitational', 'caused', '1)', 'frequency-independent', 'phase', 'shifts', 'strongly', 'lensed', '2)', 'frequency-dependent', 'modulation', 'amplitude', 'phase', 'due', 'masses.', 'None', 'these', 'searches', 'yields', 'significant', 'evidence', 'lensing.', 'use', 'non-detection', 'gravitational-wave', 'lensing', 'constrain', 'lensing', 'rate', 'based', 'latest', 'merger-rate', 'estimates', 'fraction', 'matter', 'composed', 'compact', 'objects.']\n",
      "['Some', 'hydrogen-poor', 'supernovae', '(SNe)', 'found', 'undergo', 'interaction', 'with', 'circumstellar', 'matter', '(CSM)', 'may', 'originate', 'from', 'mass', 'eruption(s)', 'just', 'core-collapse.', 'model', 'interaction', 'between', 'remaining', 'star', 'bound', 'part', 'erupted', 'CSM', 'eventually', 'fall', 'back', 'star.', 'while', 'fallback', 'initially', 'results', 'continuous', 'CSM', 'down', 'feedback', 'processes', 'from', 'star', 'push', 'CSM', 'large', 'radii', '10^{15}$', 'cm', 'from', 'several', 'years', 'eruption.', 'latter', 'case,', 'tenuous', 'bubble', 'surrounded', 'dense', 'detached', 'CSM', 'extending', '$\\\\gtrsim', 'cm', 'expected.', 'Our', 'model', 'offers', 'natural', 'unifying', 'explanation', 'diverse', 'CSM', 'structures', 'seen', 'hydrogen-poor', 'SNe,', 'such', 'Type', 'Ibn/Icn', 'SNe', 'show', 'CSM', 'signatures', 'soon', 'explosion,', 'recently', 'discovered', 'Type', 'SNe', '2021ocs', '2022xxf', '(\"the', 'Bactrian\")', 'with', 'CSM', 'signatures', 'seen', 'only', 'times.']\n",
      "['measurement', 'nuclear', 'neutrinoless', 'double-beta', 'decay', 'would', 'result', 'particle', 'physics.', 'observation', 'such', 'decay', 'would', 'neutrinos', 'their', 'own', 'antiparticles,', 'help', 'study', 'mass', 'neutrinos,', 'explore', 'origin', 'their', 'mass,', 'may', 'explain', 'matter-antimatter', 'asymmetry', 'our', 'universe', 'violation', 'lepton', 'propose', 'develop', 'time', 'projection', 'chamber', '(TPC)', 'using', '82SeF6', 'gas', 'top-metal', 'silicon', 'sensors', 'read-out', 'Jinping', 'Underground', 'Laboratory', '(CJPL),', 'search', 'neutrinoless', 'decay', '82Se,', 'called', 'NvDEx', 'experiment.', 'Besides', 'located', 'CJPL', \"world's\", 'deepest', 'rock', 'shielding,', 'NvDEx', 'combines', 'advantages', 'high', 'value', '(2.996', 'MeV)', '82Se', \"TPC's\", 'ability', 'distinguish', 'signal', 'events', 'using', 'their', 'different', 'topological', 'characteristics.', 'These', 'give', 'unique', 'great', 'potential', 'low', 'background', 'high', 'sensitivity.', 'NvDEx', 'experiment', 'phase', 'with', '100', 'kg', 'SeF6', 'gas,', 'being', 'built', 'planned', 'complete', 'with', 'installation', 'CJPL', 'around', 'year', '2025.', 'This', 'report', 'introduce', 'neutrinoless', 'double-beta', 'decay', 'physics,', 'NvDEx', 'concept', 'advantages,', 'schematic', 'design', 'NvDEx-100', 'its', 'sub-systems,', 'well', 'background', 'sensitivity', 'estimation', 'it.']\n"
     ]
    }
   ],
   "source": [
    "trivial_words_list_default = ['and','by','a','the','',  '','of','in','on','it','after',\n",
    "                              'for','ever','never','since','at','to','too','e.g.','are',\n",
    "                              'nm','is','as','we','i','go','not','can','be','that']\n",
    "\n",
    "summaries_papers_wordlist_nontrivial = filter_nontrivial_words_from_papers(summaries,trivial_words_list=trivial_words_list_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2ba05e0-1d01-4306-aff4-1a199aa11f28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_0_2304.08362v1.pdf\n"
     ]
    }
   ],
   "source": [
    "idlist_total = get_arxiv_id_papers(ids)\n",
    "\n",
    "\n",
    "save_articles_as_pdf(index_article_list =[0],ids=ids,save_papers=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
