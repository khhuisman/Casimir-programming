{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b5ed144-aadd-4a9c-a195-91b36e1ac9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## “Thank you to arXiv for use of its open access interoperability.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d507d25-5c7a-41d3-9ec5-e82b8bdcaf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib, urllib.request\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1a65844-5e67-45e5-9195-2b894db0946f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_articles_of_day(day=None, num_articles=10):\n",
    "    \"\"\"\n",
    "    Downloads the titles and summaries of a given date in the condensed matter category. \n",
    "    If no inputs are given, it will do today's date and 10 articles\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    day : date.time format\n",
    "        A given date\n",
    "    num_articles : int\n",
    "                    The number of articles requested\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    titles : bs4 ResultSet\n",
    "            Contains all titles requested, can be indexed with []\n",
    "    summaries : bs4 ResultSet\n",
    "                Contains all abstracts belonging to the titles. \n",
    "    \n",
    "    \"\"\"\n",
    "    if day==None:\n",
    "        day = date.today()\n",
    "\n",
    "    tomorrow=day+datetime.timedelta(days=1)\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:condensed%20matter&submittedDate:[{day}+TO+{tomorrow}]&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending'\n",
    "    data = urllib.request.urlopen(url)\n",
    "    summaries = BeautifulSoup(data, 'html.parser').find_all('summary')\n",
    "    titles = BeautifulSoup(data, 'html.parser').find_all('title')\n",
    "\n",
    "    return titles, summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0244a934-60f8-48f5-b78c-b1064beb27cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trivial_words_list_default = ['and','a','the','','of','in','on','it','after','for','ever','never','since','at','to','too']\n",
    "\n",
    "def filter_out_non_trivial_words(wordlist,trivial_words_list=trivial_words_list_default):\n",
    "    '''\n",
    "    \n",
    "    Function that removes trivial words from a list of words. \n",
    "    \n",
    "    Input:\n",
    "    wordlist            = list of strings, may be lowercase or uppercase \n",
    "    trivial_words_list  = list of strings that should be removed from input \"wordlist\"\n",
    "    Ouput:\n",
    "    wordlist_nontrivial = list of strings where trivial words are removed.\n",
    "    '''\n",
    "    \n",
    "    wordlist_nontrivial = []\n",
    "    \n",
    "    ## conver input words to lowercase\n",
    "    wordlist_lower = [ element.lower() for element in wordlist]\n",
    "    \n",
    "    for i in range(len(wordlist_lower)):\n",
    "        word =  wordlist_lower[i]\n",
    "\n",
    "        ## check if word is a trivial word\n",
    "        if word not in trivial_words_list:\n",
    "            wordlist_nontrivial.append(wordlist[i])\n",
    "\n",
    "    return wordlist_nontrivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de07f7a6-7f11-4d73-b577-a91d7e0af08f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Code converts the titles of input data to a list of strings\n",
    "\n",
    "splitted_strings_list = []\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    title = titles[i]\n",
    "    # print(title)\n",
    "    if i > 0:\n",
    "        # print(title.string)\n",
    "        string_splitted = re.split(' ', title.string)\n",
    "        splitted_strings_list.append(string_splitted)\n",
    "        print(string_splitted)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0810aa00-d6f2-4564-a2b1-6f5ca2f1f7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### For every paper, filter trivial words from the title\n",
    "\n",
    "wordlist_nontrivial_papers = []\n",
    "\n",
    "for index_paper in range(len(splitted_strings_list)):\n",
    "    wordlist = splitted_strings_list[index_paper]\n",
    "    wordlist_nontrivial = filter_out_non_trivial_words(wordlist,trivial_words_list=trivial_words_list_default)\n",
    "    \n",
    "    print(wordlist_nontrivial)\n",
    "    wordlist_nontrivial_papers.append(wordlist_nontrivial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
