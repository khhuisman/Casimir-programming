{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2b5ed144-aadd-4a9c-a195-91b36e1ac9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## “Thank you to arXiv for use of its open access interoperability.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d507d25-5c7a-41d3-9ec5-e82b8bdcaf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib, urllib.request\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da32b16-0638-4000-b1d8-4328153cff80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### To install: open terminal and run: \"pip install arxiv\"\n",
    "## For saving paper's pdfs\n",
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2e72f9-2d1b-4e1c-b25b-41dc59c9b72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paper = next(arxiv.Search(id_list=[\"1605.08386v1\"]).results())\n",
    "# paper.download_pdf(filename=\"downloaded-paper.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f8eec99-aa0c-403e-8af2-13ff7d89d130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_articles_of_day(day=None, num_articles=10):\n",
    "    \"\"\"\n",
    "    Downloads the titles and summaries of a given date in the condensed matter category. \n",
    "    If no inputs are given, it will do today's date and 10 articles\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    day : date.time format\n",
    "        A given date\n",
    "    num_articles : int\n",
    "                    The number of articles requested\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    titles : bs4 ResultSet\n",
    "            Contains all titles requested, can be indexed with []\n",
    "    summaries : bs4 ResultSet\n",
    "                Contains all abstracts belonging to the titles. \n",
    "    \n",
    "    \"\"\"\n",
    "    if day==None:\n",
    "        day = date.today()\n",
    "\n",
    "    tomorrow=day+datetime.timedelta(days=1)\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:condensed%20matter&submittedDate:[{day}+TO+{tomorrow}]&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending'\n",
    "    data = urllib.request.urlopen(url)\n",
    "    Bsoup = BeautifulSoup(data, 'html.parser')\n",
    "    titles,summaries,ids =  Bsoup.find_all('title'), Bsoup.find_all('summary'),Bsoup.find_all('id')\n",
    "\n",
    "    return titles, summaries,ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e88a8057-faf9-4cf8-b3dd-82feb0eb6c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "titles, summaries,ids = download_articles_of_day(day=None, num_articles=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0244a934-60f8-48f5-b78c-b1064beb27cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trivial_words_list_default = ['and','a','the','','of','in','on','it','after','for','ever','never','since','at','to','too']\n",
    "\n",
    "def filter_out_non_trivial_words(wordlist,trivial_words_list=trivial_words_list_default):\n",
    "    '''\n",
    "    Function that removes trivial words from a list of words. \n",
    "    Input:\n",
    "    wordlist            = list of strings, may be lowercase or uppercase \n",
    "    trivial_words_list  = list of lowercase strings that should be removed from input \"wordlist\"\n",
    "    Ouput:\n",
    "    wordlist_nontrivial = list of strings where trivial words are removed.\n",
    "    '''\n",
    "    wordlist_nontrivial = []\n",
    "        \n",
    "    for i in range(len(wordlist)):\n",
    "        word =  wordlist[i]\n",
    "\n",
    "        ## check if word is a trivial word\n",
    "        ## conver input words to lowercase and remove '\\n' characters (if present)\n",
    "        if word.lower().strip('\\n') not in trivial_words_list:\n",
    "            wordlist_nontrivial.append(word.strip('\\n'))\n",
    "\n",
    "    return wordlist_nontrivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0810aa00-d6f2-4564-a2b1-6f5ca2f1f7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### For every paper, filter trivial words from the title\n",
    "\n",
    "def filter_nontrivial_words_from_papers(input_data,trivial_words_list=trivial_words_list_default):\n",
    "    \n",
    "    \"\"\"\n",
    "    A list of unsplitted titles/abstracts for every paper.\n",
    "    For each paper the title/abstract is splitted and all non-trivial words are removed.\n",
    "    Output is a list of words for every paper\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : list of of unsplitted titles/abstracts for every paper.\n",
    "    trivial_words_list : list of lowercase trivial words that should be removed \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of non-trivial words for every abstract/title of every paper.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### input data is splitted.\n",
    "    splitted_strings_list = []\n",
    "    for i in range(len(input_data)):\n",
    "        title = input_data[i]\n",
    "\n",
    "        ## skip the first element\n",
    "        if i > 0:\n",
    "            # print(title.string)\n",
    "            ## seperate string on ' ' & '\\n' characters\n",
    "            string_splitted = re.split(' ', title.string)\n",
    "            string_splitted = [ re.split('\\n', element)[0]  for element in string_splitted ]\n",
    "            # print(string_splitted)\n",
    "            splitted_strings_list.append(string_splitted)\n",
    "            \n",
    "    \n",
    "    print('------')\n",
    "    ### from this data trivial words are removed. \n",
    "    wordlist_nontrivial_paper = []\n",
    "\n",
    "    for index_paper in range(len(splitted_strings_list)):\n",
    "        wordlist            = splitted_strings_list[index_paper]\n",
    "        wordlist_nontrivial = filter_out_non_trivial_words(wordlist,trivial_words_list)\n",
    "\n",
    "        print(wordlist_nontrivial)\n",
    "        wordlist_nontrivial_paper.append(wordlist_nontrivial)\n",
    "        \n",
    "    return wordlist_nontrivial_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d904d4df-60f3-4f24-ab08-4f5d6fb93577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_arxivID_of_papers(ids):\n",
    "    \n",
    "    \"\"\"\n",
    "    A list of internet links including the ArXiv ids is converted to a list with only the arxiv ids.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ids : list of internet links including the ArXiv ids for every paper.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of ArXiv ids according to the format: \"YYMM.NNNNNv{versionumber}\" for every abstract/title of every paper. YY = year, MM = month. NNNNN = som identifier number \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    idlist_total = []\n",
    "    for i in range(len(ids)):\n",
    "            id1 = ids[i]\n",
    "\n",
    "            ## skip the first element\n",
    "            if i > 0:\n",
    "                # print(id1.string)\n",
    "                ## seperate string on '/' characters\n",
    "                string_seperated = re.split('/', id1.string)\n",
    "                idlist_pdf = idlist_converted[4]\n",
    "                # print(idlist_pdf)\n",
    "\n",
    "                #### ArXiv id is given by: YYMM.NNNNNv1 therefore when seperate it should have length 14.\n",
    "                ### See: https://info.arxiv.org/help/arxiv_identifier.html#new\n",
    "                numberlist = re.split('',idlist_pdf)\n",
    "                assert len(numberlist) == 14, 'This is not the ArXiv id, pdf file cannot be saved'\n",
    "\n",
    "                idlist_total.append(idlist_pdf)\n",
    "\n",
    "                # year_index  = 10*int(numberlist[1]) + int(numberlist[2])\n",
    "                # month_index = 10*int(numberlist[3]) + int(numberlist[4])\n",
    "                \n",
    "                \n",
    "    return idlist_total\n",
    "\n",
    "\n",
    "def save_articles_as_pdf(index_article_list,\n",
    "                         ids,save_papers=\n",
    "                        False):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Saves interesting papers  as .pdf file in the current repository.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index_article_list : list of indices corresponding to the papers that should be saved as pdf.\n",
    "    ids         : list of internet links including the ArXiv ids for every paper.\n",
    "    save_papers : boolean, if True papers are saved. If False they are not saved.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    prints article's filename of the saved papers.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    idlist_total = get_arxivID_of_papers(ids)\n",
    "    \n",
    "    ## Some checks\n",
    "    assert max(index_article_list) <= len(ids), 'Index of paper does not exist. All indices should be smaller than {} '.format(len(ids))\n",
    "    assert min(index_article_list) >= 0, 'Negative index for paper is not allowed.'\n",
    "    \n",
    "    for paper_index in index_article_list:\n",
    "        article_id  = idlist_total[paper_index]\n",
    "        paper = next(arxiv.Search(id_list=[article_id]).results())\n",
    "        \n",
    "        ## name of file\n",
    "        filename = 'paper_' + str(paper_index) + '_' + article_id + '.pdf'\n",
    "        print(filename)\n",
    "        if save_papers == True:\n",
    "            paper.download_pdf(filename=filename)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5eba3a93-8822-44aa-9541-537523ff7e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summaries[0]\n",
    "\n",
    "# # print(summaries[0].string)\n",
    "# print(re.split(' ', summaries[0].string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de07f7a6-7f11-4d73-b577-a91d7e0af08f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "['Symmetry', 'Fractionalized', '(Irrationalized)', 'Fusion', 'Rules', 'Two', 'Domain-Wall', 'Verlinde', 'Formulae']\n",
      "['Signatures', 'Fractional', 'Quantum', 'Anomalous', 'Hall', 'States', 'Twisted', 'MoTe2', 'Bilayer']\n",
      "['Effective', 'electric', 'field:', 'quantifying', 'sensitivity', 'searches', 'new', 'P,T-odd', 'physics', 'with', 'EuCl$_3\\\\cdot$6H$_2$O']\n",
      "['Big', 'Bang', 'initial', 'conditions', 'self-interacting', 'hidden', 'dark', 'matter']\n",
      "['Multi-Purpose', 'Platform', 'Analog', 'Quantum', 'Simulation']\n",
      "['Exciton', 'band', 'structure', 'V$_2$O$_5$']\n",
      "['first', 'application', 'machine', 'deep', 'learning', 'background', 'rejection', 'ALPS', 'II', 'TES', 'detector']\n",
      "['Search', 'gravitational-lensing', 'signatures', 'full', 'third', 'observing', 'run', 'LIGO-Virgo', 'network']\n",
      "['Detached', 'Continuous', 'Circumstellar', 'Matter', 'Type', 'Ibc', 'Supernovae', 'from', 'Mass', 'Eruption']\n",
      "['NvDEx-100', 'Conceptual', 'Design', 'Report']\n"
     ]
    }
   ],
   "source": [
    "title_paper_wordlist_nontrivial_paper = filter_nontrivial_words_from_papers(titles,trivial_words_list=trivial_words_list_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "651d4398-cd2c-447d-a894-5d6ce9699a06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "['interplay', 'between', 'spontaneous', 'symmetry', 'breaking', 'topology', 'result', 'exotic', 'quantum', 'states', 'matter.', 'celebrated', 'example', 'quantum', 'Hall', '(QAH)', 'state,', 'which', 'exhibits', 'an', 'integer', 'quantum', 'Hall', 'effect', 'magnetic', 'field', 'thanks', 'its', 'intrinsic', 'ferromagnetism.', 'presence', 'electron-electron', 'interactions,', 'exotic', 'fractional-QAH', '(FQAH)', 'states', 'magnetic', 'field', 'emerge.', 'These', 'states', 'could', 'host', 'fractional', 'excitations,', 'non-Abelian', 'anyons', '-', 'crucial', 'building', 'blocks', 'topological', 'quantum', 'Flat', 'Chern', 'bands', 'widely', 'considered', 'desirable', 'venue', 'FQAH', 'state.', 'this', 'purpose,', 'twisted', 'transition', 'metal', 'homobilayers', 'rhombohedral', 'stacking', 'have', 'recently', 'been', 'promising', 'material', 'platform.', 'Here,', 'report', 'experimental', 'FQAH', 'states', '3.7-degree', 'twisted', 'MoTe2', 'bilayer.', 'Magnetic', 'dichroism', 'measurements', 'reveal', 'robust', 'ferromagnetic', 'states', 'hole', 'filled', \"moir\\\\'e\", 'minibands.', 'Using', 'trion', 'photoluminescence', 'obtain', 'Landau', 'fan', 'diagram', 'which', 'shows', 'linear', 'shifts', 'carrier', 'corresponding', 'v=-2/3', '-3/5', 'ferromagnetic', 'states', 'with', 'magnetic', 'field.', 'These', 'shifts', 'match', 'Streda', 'formula', 'dispersion', 'states', 'with', 'fractionally', 'quantized', 'Hall', 'conductance', '-2/3$e^2/h$', 'respectively.', 'Moreover,', 'v=-1', 'state', 'exhibits', 'dispersion', 'Chern', 'number', '-1,', 'consistent', 'with', 'predicted', 'QAH', 'state.', 'several', 'non-ferromagnetic', 'states', 'electron', 'doping', 'side', 'do', 'i.e.,', 'trivial', 'correlated', 'insulators.', 'observed', 'topological', 'further', 'electrically', 'driven', 'into', 'topologically', 'trivial', 'states.', 'findings', 'provide', 'clear', 'evidence', 'long-sought', 'FQAH', 'states,', 'putting', 'MoTe2', \"moir\\\\'e\", 'superlattices', 'fascinating', 'platform', 'exploring', 'excitations.']\n",
      "['Laboratory-scale', 'precision', 'experiments', 'promising', 'approach', 'searching', 'physics', 'beyond', 'standard', 'model.', 'Non-centrosymmetric', 'solids', 'offer', 'statistical', 'sensitivity', 'efforts', 'search', 'new', 'fields,', 'whose', 'violate', 'discrete', 'parity', 'time-reversal', 'symmetries.', 'One', 'electric', 'Cosmic', 'Axion', 'Spin', 'Precession', 'Experiment', '(CASPEr-e),', 'sensitive', 'defining', 'interaction', 'QCD', 'axion', 'dark', 'matter', 'gluons', 'atomic', 'nuclei.', 'effective', 'electric', 'field', 'parameter', 'quantifies', 'sensitivity', 'such', 'experiments', 'new', 'physics.', 'describe', 'theoretical', 'approach', 'calculating', 'effective', 'electric', 'field', 'sites', 'ionic', 'insulating', 'solids.', 'consider', 'specific', 'EuCl$_3\\\\cdot$6H$_2$O', 'crystal,', 'which', 'particularly', 'promising', 'optimistic', 'estimate', 'effective', 'electric', 'field', 'isotope', 'this', 'crystal', '10', 'MV/cm.', 'calculation', 'uncertainty', 'two', 'orders', 'magnitude,', 'dominated', 'evaluation', 'nuclear', 'Schiff', 'moment.']\n",
      "['variety', 'supergravity', 'string', 'models', 'involve', 'hidden', 'sectors', 'where', 'sectors', 'may', 'couple', 'feebly', 'with', 'visible', 'sectors', 'via', 'variety', 'While', 'coupling', 'hidden', 'sector', 'visible', 'sector', 'its', 'coupling', 'inflaton', 'largely', 'unknown.', 'could', 'couple', 'feebly', 'with', 'same', 'strength', 'visible', 'sector', 'which', 'would', 'result', 'either', 'or', 'hot', 'hidden', 'sector', 'end', 'reheating.', 'These', 'two', 'possibilities', 'lead', 'significantly', 'different', 'outcomes', 'observables.', 'investigate', 'thermal', 'evolution', 'two', 'sectors', 'cosmologically', 'consistent', 'hidden', 'dark', 'matter', 'model', 'where', 'hidden', 'sector', 'visible', 'sector', 'coupled', 'their', 'thermal', 'evolution', 'occurs', 'without', 'assumption', 'entropy', 'conservation', 'each', 'sector.', 'Within', 'this', 'framework', 'analyze', 'phenomena', 'illustrate', 'their', 'dependence', 'initial', 'conditions.', 'include', 'allowed', 'parameter', 'space', 'models,', 'dark', 'matter', 'relic', 'density,', 'matter', 'cross', 'section,', 'effective', 'massless', 'neutrino', 'species', 'BBN', 'self-interacting', 'dark', 'matter', 'cross-section,', 'where', 'self-interaction', 'occurs', 'exchange', 'dark', 'photon,', 'Sommerfeld', 'enhancement.', 'Finally', 'fits', 'dependence', 'dark', 'matter', 'cross', 'sections', 'from', 'galaxy', 'scales', 'galaxy', 'clusters', 'given.', 'analysis', 'indicates', 'significant', 'effects', 'initial', 'conditions', 'observables', 'listed', 'above.', 'analysis', 'out', 'within', 'framework', 'where', 'dark', 'matter', 'constituted', 'dark', 'mediation', 'between', 'visible', 'hidden', 'sector', 'occurs', 'via', 'exchange', 'dark', 'photons.', 'techniques', 'discussed', 'here', 'may', 'have', 'wider', 'class', 'hidden', 'sector', 'models', 'using', 'different', 'between', 'visible', 'hidden', 'sectors', 'explore', 'impact', 'Bang', 'initial', 'conditions', 'observable', 'physics.']\n",
      "['Atom-based', 'quantum', 'simulators', 'have', 'had', 'tremendous', 'success', 'tackling', 'quantum', 'many-body', 'problems,', 'owing', 'precise', 'dynamical', 'they', 'provide', 'over', \"systems'\", 'parameters.', 'They', 'are,', 'however,', 'optimized', 'address', 'specific', 'type', 'problems.', 'Here,', 'present', 'implementation', '$^6$Li-based', 'quantum', 'gas', 'platform', 'provides', 'capabilities', 'able', 'address', 'variety', 'quantum', 'many-body', 'Our', 'two-chamber', 'architecture', 'relies', 'robust', 'easy-to-implement', 'gray', 'molasses', 'optical', 'transport', 'from', 'laser-cooling', 'chamber', 'glass', 'cell', 'with', 'excellent', 'optical', 'access.', 'There,', 'first', 'create', 'unitary', 'superfluids', 'three-dimensional', 'axially', 'symmetric', 'harmonic', 'trap', 'them', 'using', 'situ', 'thermometry,', 'reaching', 'temperatures', 'below', '20', 'nK.', 'allows', 'us', 'enter', 'deep', 'superfluid', 'regime', 'with', 'samples', 'extreme', 'where', 'interparticle', 'spacing', 'sufficiently', 'large', 'direct', 'imaging.', 'Secondly,', 'generate', 'optical', 'lattice', 'potentials', 'with', 'honeycomb', 'geometry', 'which', 'study', 'diffraction', 'molecular', 'condensates,', 'show', 'how', 'going', 'beyond', 'Kapitza-Dirac', 'regime', 'us', 'unambiguously', 'distinguish', 'between', 'two', 'geometries.', 'With', 'probe', 'quantum', 'many-body', 'physics', 'both', 'discrete', 'continuous', 'its', 'suitability', 'bulk', 'single-atom', 'imaging,', 'our', 'setup', 'an', 'important', 'step', 'towards', 'achieving', 'wide-scope', 'quantum', 'simulator.']\n",
      "['Excitonic', 'effects', 'due', 'correlation', 'electrons', 'holes', 'excited', 'matter', 'dominate', 'optical', 'spectra', 'many', 'interesting', 'materials.', 'usually', 'studied', 'long-wavelength', 'limit.', 'Here', 'investigate', 'non-vanishing', 'momentum', 'transfer,', 'corresponding', 'shorter', 'calculate', 'exciton', 'dispersion', 'prototypical', 'layered', 'V$_2$O$_5$', 'solving', 'Bethe-Salpeter', 'equation', 'many-body', 'theory.', 'discuss', 'change', 'excitation', 'energy', 'intensity', 'function', 'wavevector', 'bright', 'dark', 'excitons,', 'respectively,', 'origin', 'excitons', 'along', 'their', 'dispersion.', 'highlight', 'role', 'electron-hole', 'exchange', 'with', 'its', 'impact', 'exciton', 'singlet-triplet', 'splitting', 'difference', 'between', 'part', 'macroscopic', 'dielectric', 'function', 'loss', 'function.']\n",
      "['Axions', 'axion-like', 'particles', 'hypothetical', 'particles', 'predicted', 'standard', 'model', 'promising', 'cold', 'dark', 'matter', 'candidates.', 'Any', 'Light', 'Particle', 'Search', '(ALPS', 'II)', 'experiment', 'experiment', 'aims', 'produce', 'these', 'particles', 'strong', 'light', 'source', 'magnetic', 'field', 'subsequently', 'detect', 'them', 'reconversion', 'into', 'photons.', 'With', 'an', 'expected', 'rate', '$\\\\sim$', '1', 'photon', 'per', 'sensitive', 'detection', 'scheme', 'needs', 'employed', 'characterized.', 'One', 'detector', 'based', 'transition', 'edge', 'sensor', '(TES).', 'Here,', 'machine', 'deep', 'learning', 'algorithms', 'rejection', 'events', 'recorded', 'with', 'TES.', 'also', 'present', 'first', 'application', 'neural', 'networks', 'classify', 'time', 'series', 'data', 'measured', 'with']\n",
      "['Gravitational', 'lensing', 'massive', 'objects', 'along', 'line', 'sight', 'causes', 'distortions', 'gravitational', 'wave-signals;', 'such', 'distortions', 'may', 'information', 'about', 'fundamental', 'physics,', 'cosmology', 'astrophysics.', 'work,', 'have', 'extended', 'search', 'lensing', 'signatures', 'all', 'binary', 'hole', 'events', 'from', 'third', 'observing', 'run', 'LIGO--Virgo', 'network.', 'repeated', 'signals', 'from', 'strong', 'lensing', '1)', 'performing', 'targeted', 'subthreshold', 'signals,', '2)', 'calculating', 'degree', 'overlap', 'amongst', 'intrinsic', 'parameters', 'sky', 'location', 'pairs', 'signals,', '3)', 'comparing', 'spectrograms', 'amongst', 'pairs', 'signals,', '4)', 'performing', 'Bayesian', 'analysis', 'takes', 'into', 'account', 'selection', 'effects', 'knowledge.', 'also', 'search', 'distortions', 'gravitational', 'caused', '1)', 'frequency-independent', 'phase', 'shifts', 'strongly', 'lensed', '2)', 'frequency-dependent', 'modulation', 'amplitude', 'phase', 'due', 'masses.', 'None', 'these', 'searches', 'yields', 'significant', 'evidence', 'lensing.', 'use', 'non-detection', 'gravitational-wave', 'lensing', 'constrain', 'lensing', 'rate', 'based', 'latest', 'merger-rate', 'estimates', 'fraction', 'matter', 'composed', 'compact', 'objects.']\n",
      "['Some', 'hydrogen-poor', 'supernovae', '(SNe)', 'found', 'undergo', 'interaction', 'with', 'circumstellar', 'matter', '(CSM)', 'may', 'originate', 'from', 'mass', 'eruption(s)', 'just', 'core-collapse.', 'model', 'interaction', 'between', 'remaining', 'star', 'bound', 'part', 'erupted', 'CSM', 'eventually', 'fall', 'back', 'star.', 'while', 'fallback', 'initially', 'results', 'continuous', 'CSM', 'down', 'feedback', 'processes', 'from', 'star', 'push', 'CSM', 'large', 'radii', '10^{15}$', 'cm', 'from', 'several', 'years', 'eruption.', 'latter', 'case,', 'tenuous', 'bubble', 'surrounded', 'dense', 'detached', 'CSM', 'extending', '$\\\\gtrsim', 'cm', 'expected.', 'Our', 'model', 'offers', 'natural', 'unifying', 'explanation', 'diverse', 'CSM', 'structures', 'seen', 'hydrogen-poor', 'SNe,', 'such', 'Type', 'Ibn/Icn', 'SNe', 'show', 'CSM', 'signatures', 'soon', 'explosion,', 'recently', 'discovered', 'Type', 'SNe', '2021ocs', '2022xxf', '(\"the', 'Bactrian\")', 'with', 'CSM', 'signatures', 'seen', 'only', 'times.']\n",
      "['measurement', 'nuclear', 'neutrinoless', 'double-beta', 'decay', 'would', 'result', 'particle', 'physics.', 'observation', 'such', 'decay', 'would', 'neutrinos', 'their', 'own', 'antiparticles,', 'help', 'study', 'mass', 'neutrinos,', 'explore', 'origin', 'their', 'mass,', 'may', 'explain', 'matter-antimatter', 'asymmetry', 'our', 'universe', 'violation', 'lepton', 'propose', 'develop', 'time', 'projection', 'chamber', '(TPC)', 'using', '82SeF6', 'gas', 'top-metal', 'silicon', 'sensors', 'read-out', 'Jinping', 'Underground', 'Laboratory', '(CJPL),', 'search', 'neutrinoless', 'decay', '82Se,', 'called', 'NvDEx', 'experiment.', 'Besides', 'located', 'CJPL', \"world's\", 'deepest', 'rock', 'shielding,', 'NvDEx', 'combines', 'advantages', 'high', 'value', '(2.996', 'MeV)', '82Se', \"TPC's\", 'ability', 'distinguish', 'signal', 'events', 'using', 'their', 'different', 'topological', 'characteristics.', 'These', 'give', 'unique', 'great', 'potential', 'low', 'background', 'high', 'sensitivity.', 'NvDEx', 'experiment', 'phase', 'with', '100', 'kg', 'SeF6', 'gas,', 'being', 'built', 'planned', 'complete', 'with', 'installation', 'CJPL', 'around', 'year', '2025.', 'This', 'report', 'introduce', 'neutrinoless', 'double-beta', 'decay', 'physics,', 'NvDEx', 'concept', 'advantages,', 'schematic', 'design', 'NvDEx-100', 'its', 'sub-systems,', 'well', 'background', 'sensitivity', 'estimation', 'it.']\n"
     ]
    }
   ],
   "source": [
    "trivial_words_list_default = ['and','by','a','the','',  '','of','in','on','it','after',\n",
    "                              'for','ever','never','since','at','to','too','e.g.','are',\n",
    "                              'nm','is','as','we','i','go','not','can','be','that']\n",
    "\n",
    "summaries_papers_wordlist_nontrivial = filter_nontrivial_words_from_papers(summaries,trivial_words_list=trivial_words_list_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2ba05e0-1d01-4306-aff4-1a199aa11f28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_0_2304.08362v1.pdf\n"
     ]
    }
   ],
   "source": [
    "idlist_total = get_arxiv_id_papers(ids)\n",
    "\n",
    "\n",
    "save_articles_as_pdf(index_article_list =[0],ids=ids,save_papers=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
