{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2b5ed144-aadd-4a9c-a195-91b36e1ac9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## “Thank you to arXiv for use of its open access interoperability.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d507d25-5c7a-41d3-9ec5-e82b8bdcaf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib, urllib.request\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da32b16-0638-4000-b1d8-4328153cff80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arxiv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m### To install: open terminal and run: \"pip install arxiv\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m## For saving paper's pdfs\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39marxiv\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'arxiv'"
     ]
    }
   ],
   "source": [
    "### To install: open terminal and run: \"pip install arxiv\"\n",
    "## For saving paper's pdfs\n",
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8eec99-aa0c-403e-8af2-13ff7d89d130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_articles_of_day(day=None, num_articles=10):\n",
    "    \"\"\"\n",
    "    Downloads the titles and summaries of a given date in the condensed matter category. \n",
    "    If no inputs are given, it will do today's date and 10 articles\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    day : date.time format\n",
    "        A given date\n",
    "    num_articles : int\n",
    "                    The number of articles requested\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    titles : bs4 ResultSet\n",
    "            Contains all titles requested, can be indexed with []\n",
    "    summaries : bs4 ResultSet\n",
    "                Contains all abstracts belonging to the titles. \n",
    "    \n",
    "    \"\"\"\n",
    "    if day==None:\n",
    "        day = date.today()\n",
    "\n",
    "    tomorrow=day+datetime.timedelta(days=1)\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:condensed%20matter&submittedDate:[{day}+TO+{tomorrow}]&start=0&max_results={num_articles}&sortBy=submittedDate&sortOrder=descending'\n",
    "    data = urllib.request.urlopen(url)\n",
    "    Bsoup = BeautifulSoup(data, 'html.parser')\n",
    "    titles,summaries,ids =  Bsoup.find_all('title'), Bsoup.find_all('summary'),Bsoup.find_all('id')\n",
    "\n",
    "    return titles, summaries,ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56350a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_subset_of_articles(todays_articles, num_articles_to_show=4):\n",
    "    \"\"\"\n",
    "    Shows a subset of the articles and asks the user if they are interesting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    todays_articles : tuple\n",
    "        A tuple of the form (titles, summaries, ids)\n",
    "\n",
    "    num_articles_to_show : int, optional\n",
    "        The number of articles to show. The default is 4.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    interesting_articles : list\n",
    "        A list of the indices of the interesting articles.\n",
    "    \"\"\"\n",
    "\n",
    "    titles, summaries, _ = todays_articles\n",
    "    interesting_articles = []\n",
    "    \n",
    "    for i in range(num_articles_to_show): \n",
    "        print(f'Aritlce Number {i}')\n",
    "        print(titles[i+1].text)\n",
    "        print(summaries[i].text)\n",
    "        print()\n",
    "        while True:\n",
    "            answer = input(\"Is this article interesting? (yes/no/stop): \")\n",
    "            if answer == 'yes':\n",
    "                interesting_articles.append(i)\n",
    "                break\n",
    "            elif answer == 'no':\n",
    "                break\n",
    "            elif answer == 'stop':\n",
    "                return interesting_articles\n",
    "            else:\n",
    "                print(\"Please enter yes, no, or stop\")\n",
    "        \n",
    "    return interesting_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a614b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "trivial_words_list_default = ['and','a','the','','of','in','on','it','after','for','ever','never','since','at','to','too'\n",
    "                              , 'We', 'show', 'that', 'this', 'with', 'by', 'from', 'as', 'be', 'are', 'have', 'has', 'can', \n",
    "                              'could', 'will', 'would', 'may', 'might', 'must', 'shall', 'should', 'do', 'such', 'both', 'assume'\n",
    "                              'also', 'an', 'any', 'each', 'every', 'either', 'neither', 'other', 'another', 'such', 'same', 'several',\n",
    "                              'variable', 'various', 'well', 'where', 'which', 'while', 'wide', 'within', 'yet', 'you', 'your', 'yours', 'yourself', \n",
    "                              'but', 'been']\n",
    "\n",
    "def filter_out_non_trivial_words(wordlist,trivial_words_list=trivial_words_list_default):\n",
    "    '''\n",
    "    Function that removes trivial words from a list of words. \n",
    "    Input:\n",
    "    wordlist            = list of strings, may be lowercase or uppercase \n",
    "    trivial_words_list  = list of lowercase strings that should be removed from input \"wordlist\"\n",
    "    Ouput:\n",
    "    wordlist_nontrivial = list of strings where trivial words are removed.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Does it ignore capital letters? Right now it still includes commas after a word, maybe best if we don't include them\n",
    "    '''\n",
    "    wordlist_nontrivial = []\n",
    "        \n",
    "    for i in range(len(wordlist)):\n",
    "        word =  wordlist[i]\n",
    "\n",
    "        ## check if word is a trivial word\n",
    "        ## conver input words to lowercase and remove '\\n' characters (if present)\n",
    "        if word.lower().strip('\\n') not in trivial_words_list:\n",
    "            wordlist_nontrivial.append(word.strip('\\n'))\n",
    "\n",
    "    return wordlist_nontrivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da798c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_likely_interesting_articles(info, interesting_indices, shown_upto,\n",
    "                                trivial_words_list):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    info : tuple\n",
    "        Tuple containing titles, summaries, and ids of articles\n",
    "    interesting_indices : list\n",
    "        List of indices of interesting articles\n",
    "    shown_upto : int\n",
    "        Number of articles shown so far\n",
    "    trivial_words_list : list\n",
    "        List of trivial words to be removed from articles\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    comparison_percentages : list\n",
    "        List of percentages of interesting words in each article\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Define percentage as how many words of an article appear in the interesting\n",
    "    articles list divided by total number of words in the article. \n",
    "    \"\"\"\n",
    "\n",
    "    titles, summaries, _ = info\n",
    "    interesting_wordlist = [ ] \n",
    "    for i in interesting_indices:\n",
    "        interesting_wordlist += titles[i+1].text.split()\n",
    "        interesting_wordlist += summaries[i].text.split()\n",
    "\n",
    "    interesting_wordlist_nontrivial = filter_out_non_trivial_words(\n",
    "        interesting_wordlist,trivial_words_list)\n",
    "    \n",
    "    #sort the strings into a unique list and count the number of times each word appears\n",
    "    unique_words = np.unique(interesting_wordlist_nontrivial)\n",
    "\n",
    "    comparison_percentages = []\n",
    "    for i in range(len(summaries)-shown_upto):\n",
    "        wordlist = summaries[i+shown_upto].text.split()\n",
    "        wordlist_nontrivial = filter_out_non_trivial_words(wordlist,trivial_words_list)\n",
    "        interesting_words = len(np.nonzero(np.isin(wordlist_nontrivial, unique_words))[0])\n",
    "        comparison_percentages.append(interesting_words / len(wordlist_nontrivial))\n",
    "\n",
    "    print('The next most likely interesting article is:')\n",
    "    print()\n",
    "    print(titles[np.argmax(comparison_percentages)+shown_upto+1].text)\n",
    "    print(summaries[np.argmax(comparison_percentages)+shown_upto].text)\n",
    "    print(f'With an overlap in words of {np.max(comparison_percentages)*100:.2f}%')\n",
    "    return comparison_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45be47e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0810aa00-d6f2-4564-a2b1-6f5ca2f1f7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### For every paper, filter trivial words from the title\n",
    "\n",
    "def filter_nontrivial_words_from_papers(input_data,trivial_words_list=trivial_words_list_default):\n",
    "    \n",
    "    \"\"\"\n",
    "    A list of unsplitted titles/abstracts for every paper.\n",
    "    For each paper the title/abstract is splitted and all non-trivial words are removed.\n",
    "    Output is a list of words for every paper\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : list of of unsplitted titles/abstracts for every paper.\n",
    "    trivial_words_list : list of lowercase trivial words that should be removed \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of non-trivial words for every abstract/title of every paper.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### input data is splitted.\n",
    "    splitted_strings_list = []\n",
    "    for i in range(len(input_data)):\n",
    "        title = input_data[i]\n",
    "\n",
    "        ## skip the first element\n",
    "        if i > 0:\n",
    "            # print(title.string)\n",
    "            ## seperate string on ' ' & '\\n' characters\n",
    "            string_splitted = re.split(' ', title.string)\n",
    "            string_splitted = [ re.split('\\n', element)[0]  for element in string_splitted ]\n",
    "            # print(string_splitted)\n",
    "            splitted_strings_list.append(string_splitted)\n",
    "            \n",
    "    \n",
    "    print('------')\n",
    "    ### from this data trivial words are removed. \n",
    "    wordlist_nontrivial_paper = []\n",
    "\n",
    "    for index_paper in range(len(splitted_strings_list)):\n",
    "        wordlist            = splitted_strings_list[index_paper]\n",
    "        wordlist_nontrivial = filter_out_non_trivial_words(wordlist,trivial_words_list)\n",
    "\n",
    "        print(wordlist_nontrivial)\n",
    "        wordlist_nontrivial_paper.append(wordlist_nontrivial)\n",
    "        \n",
    "    return wordlist_nontrivial_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d904d4df-60f3-4f24-ab08-4f5d6fb93577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_arxivID_of_papers(ids):\n",
    "    \n",
    "    \"\"\"\n",
    "    A list of internet links including the ArXiv ids is converted to a list with only the arxiv ids.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ids : list of internet links including the ArXiv ids for every paper.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of ArXiv ids according to the format: \"YYMM.NNNNNv{versionumber}\" for every abstract/title of every paper. YY = year, MM = month. NNNNN = som identifier number \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    idlist_total = []\n",
    "    for i in range(len(ids)):\n",
    "            id1 = ids[i]\n",
    "\n",
    "            ## skip the first element\n",
    "            if i > 0:\n",
    "                # print(id1.string)\n",
    "                ## seperate string on '/' characters\n",
    "                string_seperated = re.split('/', id1.string)\n",
    "                idlist_pdf = idlist_converted[4]\n",
    "                # print(idlist_pdf)\n",
    "\n",
    "                #### ArXiv id is given by: YYMM.NNNNNv1 therefore when seperate it should have length 14.\n",
    "                ### See: https://info.arxiv.org/help/arxiv_identifier.html#new\n",
    "                numberlist = re.split('',idlist_pdf)\n",
    "                assert len(numberlist) == 14, 'This is not the ArXiv id, pdf file cannot be saved'\n",
    "\n",
    "                idlist_total.append(idlist_pdf)\n",
    "\n",
    "                # year_index  = 10*int(numberlist[1]) + int(numberlist[2])\n",
    "                # month_index = 10*int(numberlist[3]) + int(numberlist[4])\n",
    "                \n",
    "                \n",
    "    return idlist_total\n",
    "\n",
    "\n",
    "def save_articles_as_pdf(index_article_list,\n",
    "                         ids,save_papers=\n",
    "                        False):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Saves interesting papers  as .pdf file in the current repository.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index_article_list : list of indices corresponding to the papers that should be saved as pdf.\n",
    "    ids         : list of internet links including the ArXiv ids for every paper.\n",
    "    save_papers : boolean, if True papers are saved. If False they are not saved.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    prints article's filename of the saved papers.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    idlist_total = get_arxivID_of_papers(ids)\n",
    "    \n",
    "    ## Some checks\n",
    "    assert max(index_article_list) <= len(ids), 'Index of paper does not exist. All indices should be smaller than {} '.format(len(ids))\n",
    "    assert min(index_article_list) >= 0, 'Negative index for paper is not allowed.'\n",
    "    \n",
    "    for paper_index in index_article_list:\n",
    "        article_id  = idlist_total[paper_index]\n",
    "        paper = next(arxiv.Search(id_list=[article_id]).results())\n",
    "        \n",
    "        ## name of file\n",
    "        filename = 'paper_' + str(paper_index) + '_' + article_id + '.pdf'\n",
    "        print(filename)\n",
    "        if save_papers == True:\n",
    "            paper.download_pdf(filename=filename)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "112c5ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rzijderveld/Library/Python/3.9/lib/python/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aritlce Number 0\n",
      "Universal scaling function ansatz for finite-temperature jamming\n",
      "  We cast a nonzero-temperature analysis of the jamming transition into the\n",
      "framework of a scaling ansatz. We show that four distinct regimes for scaling\n",
      "exponents of thermodynamic derivatives of the free energy such as pressure,\n",
      "bulk and shear moduli, can be consolidated by introducing a universal scaling\n",
      "function with two branches. Both the original analysis and the scaling theory\n",
      "assume that the system always resides in a single basis in the energy\n",
      "landscape. The two branches are separated by a line $T^*(\\Delta \\phi)$ in the\n",
      "$T-\\Delta \\phi$ plane, where $\\Delta \\phi=\\phi-\\phi_c^\\Lambda$ is the deviation\n",
      "of the packing fraction from its critical, jamming value, $\\phi_c^\\Lambda$, for\n",
      "that basin. The branch for $T<T^*(\\Delta \\phi)$ reduces at $T=0$ to an earlier\n",
      "scaling ansatz that is restricted to $T=0$, $\\Delta \\phi \\ge 0$, while the\n",
      "branch for $T>T^*(\\Delta \\phi)$ reproduces exponents observed for thermal hard\n",
      "spheres. In contrast to the usual scenario for critical phenomena, the two\n",
      "branches are characterized by different exponents. We suggest that this unusual\n",
      "feature can be resolved by the existence of a dangerous irrelevant variable\n",
      "$u$, which can appear to modify exponents if the leading $u=0$ term is\n",
      "sufficiently small in the regime described by one of the two branches of the\n",
      "scaling function.\n",
      "\n",
      "\n",
      "Aritlce Number 1\n",
      "Distance-dependent emission spectrum from two qubits in a\n",
      "  strong-coupling regime\n",
      "  We study the emission spectrum of two distant qubits strongly coupled to a\n",
      "waveguide by using the numerical and analytical approaches, which are beyond\n",
      "the Markovian approximation and the rotating-wave approximation (RWA). The\n",
      "numerical approach combines the Dirac-Frenkel time-dependent variational\n",
      "principle with the multiple Davydov $D_{1}$ ansatz. A transformed RWA (TRWA)\n",
      "treatment and a standard perturbation (SP) are used to analytically calculate\n",
      "the emission spectrum. It is found that the variational approach and the TRWA\n",
      "treatment yield accurate emission spectra of the two distant qubits in certain\n",
      "strong coupling regimes while the SP breaks down. The emission spectrum is\n",
      "found to be asymmetric irrespective of the two-qubit distance and exhibits a\n",
      "single peak, doublet, and multipeaks depending on the two-qubit distance as\n",
      "well as the initial states. In sharply contrast with the single-qubit case, the\n",
      "excited-state populations of the two qubits can ultraslowly decay due to the\n",
      "subradiance even in the presence of a strong qubit-waveguide coupling, which in\n",
      "turn yields ultranarrow emission line. Our results provide insights into the\n",
      "emission spectral features of the two distant qubits in the strong light-matter\n",
      "coupling regime.\n",
      "\n",
      "\n",
      "Aritlce Number 2\n",
      "Jamming, relaxation, and memory in a structureless glass former\n",
      "  Real structural glasses form through various out-of-equilibrium processes,\n",
      "including temperature quenches, rapid compression, shear, and aging. Each of\n",
      "these processes should be formally understandable within the recently\n",
      "formulated dynamical mean-field theory of glasses, but many of the numerical\n",
      "tools needed to solve the relevant equations for sufficiently long timescales\n",
      "do not yet exist. Numerical simulations of structureless (and therefore\n",
      "mean-field-like) model glass formers can nevertheless aid searching for and\n",
      "understanding such solutions, thanks to their ability to disentangle structural\n",
      "from dimensional effects. We here study the infinite-range Mari-Kurchan model\n",
      "under simple non-equilibrium processes and compare the results with those from\n",
      "the random Lorentz gas [J. Phys. A: Math. Theor. 55 334001, (2022)], which are\n",
      "both mean-field-like and become formally equivalent in the limit of infinite\n",
      "spatial dimensions. Of particular interest are jamming from crunching and under\n",
      "instantaneous temperature quenches. The study allows for an algorithmic\n",
      "understanding of the jamming density and of its approach to the\n",
      "infinite-dimensional limit. The results provide important insight into the\n",
      "eventual solution of the dynamical mean-field theory, including onsets and\n",
      "anomalous relaxation, as well as into the various algorithmic schemes for\n",
      "jamming.\n",
      "\n",
      "\n",
      "Aritlce Number 3\n",
      "Attractor Solutions in Interacting Dark Energy Models\n",
      "  We investigate a cosmological model in which dark energy, represented by a\n",
      "quintessential scalar field, is coupled to a dark-matter perfect fluid in the\n",
      "spatially flat Friedmann-Robertson-Walker Universe. This allows an energy\n",
      "exchange in the dark sector which could happen both at early times before\n",
      "recombination era or at late times. We use the coupling function\n",
      "$Q=\\gamma\\rho_{dm}\\dot{\\varphi}$ which is induced by conformal transforming\n",
      "scalar-tensor and $f(R)$ gravity theories to Einstein frame. It is argued that\n",
      "there is a connection between this coupling function and $Q\\propto \\rho_{dm}H$.\n",
      "A dynamical analysis is used to show that there are early- and late-time\n",
      "attracting solutions for which the system evolves for a wide range of initial\n",
      "conditions. These attractors generalize the scaling solutions which have been\n",
      "already found in the non-interacting case.\n",
      "\n",
      "\n",
      "Aritlce Number 4\n",
      "Self-consistent homogenization approach for polycrystals within second\n",
      "  gradient elasticity\n",
      "  In this paper, we propose a generalized variant of Kr\\\"oner's self-consistent\n",
      "scheme for evaluation of the effective standard and gradient elastic moduli of\n",
      "polycrystalline materials within Mindlin-Toupin second-gradient elasticity\n",
      "theory. Assuming random orientation of crystallites (grains) we use an extended\n",
      "Eshelby's equivalent inclusion method and mapping conditions between the\n",
      "prescribed linear distribution of macro-strain and corresponding micro-scale\n",
      "field variables averaged over the volume and all possible orientations of\n",
      "single grain. It is found that developed self-consistent scheme predicts the\n",
      "absence of strong gradient effects at the macro-scale level for the model of\n",
      "spherical grains. However, for the more general shape of the grains, considered\n",
      "approach allows to obtain a set of non-linear relations for determination of\n",
      "all effective standard and gradient elastic moduli of polycrystals.\n",
      "\n",
      "\n",
      "Aritlce Number 5\n",
      "Free field realisation of boundary vertex algebras for Abelian gauge\n",
      "  theories in three dimensions\n",
      "  We study the boundary vertex algebras of $A$-twisted $\\mathcal{N}=4$ Abelian\n",
      "gauge theories in three dimensions. These are identified with the BRST quotient\n",
      "(semi-infinite cohomology) of collections of symplectic bosons and free\n",
      "fermions that reflect the matter content of the corresponding gauge theory. We\n",
      "develop various free field realisations for these vertex algebras which we\n",
      "propose to interpret in terms of their localisation on their associated\n",
      "varieties. We derive the free field realisations by bosonising the elementary\n",
      "symplectic bosons and free fermions and then calculating the relevant\n",
      "semi-infinite cohomology, which can be done systematically. An interesting\n",
      "feature of our construction is that for certain preferred free field\n",
      "realisations, the outer automorphism symmetry of the vertex algebras in\n",
      "question (which are identified with the symmetries of the Coulomb branch in the\n",
      "infrared) are made manifest.\n",
      "\n",
      "\n",
      "Aritlce Number 6\n",
      "Searching for Heavy Dark Matter near the Planck Mass with XENON1T\n",
      "  Multiple viable theoretical models predict heavy dark matter particles with a\n",
      "mass close to the Planck mass, a range relatively unexplored by current\n",
      "experimental measurements. We use 219.4 days of data collected with the XENON1T\n",
      "experiment to conduct a blind search for signals from Multiply-Interacting\n",
      "Massive Particles (MIMPs). Their unique track signature allows a targeted\n",
      "analysis with only 0.05 expected background events from muons. Following\n",
      "unblinding, we observe no signal candidate events. This work places strong\n",
      "constraints on spin-independent interactions of dark matter particles with a\n",
      "mass between 1$\\times$10$^{12}\\,$GeV/c$^2$ and 2$\\times$10$^{17}\\,$GeV/c$^2$.\n",
      "In addition, we present the first exclusion limits on spin-dependent\n",
      "MIMP-neutron and MIMP-proton cross-sections for dark matter particles with\n",
      "masses close to the Planck scale.\n",
      "\n",
      "\n",
      "Aritlce Number 7\n",
      "Universal interface fluctuations in the contact process\n",
      "  We study the interface representation of the contact process (CP) at its\n",
      "directed-percolation critical point, where the scaling properties of the\n",
      "interface can be related to those of the original particle model.\n",
      "Interestingly, such a behavior happens to be intrinsically anomalous and more\n",
      "complex than that described by the standard Family-Vicsek dynamic scaling\n",
      "Ansatz of surface kinetic roughening. We expand on a previous numerical study\n",
      "by Dickman and Mu\\~noz [Phys. Rev. E 62, 7632 (2000)] to fully characterize the\n",
      "kinetic roughening universality class for interface dimensions $d=1, 2$, and 3.\n",
      "Beyond obtaining scaling exponent values, we characterize the interface\n",
      "fluctuations via their probability density function (PDF) and covariance, seen\n",
      "to display universal properties which are qualitatively similar to those\n",
      "recently assessed for the Kardar-Parisi-Zhang (KPZ) and other important\n",
      "universality classes of kinetic roughening. Quantitatively, while for $d=1$ the\n",
      "interface covariance seems to be well described by the KPZ, Airy$_1$\n",
      "covariance, no such agreement occurs in terms of the fluctuation PDF nor the\n",
      "scaling exponents.\n",
      "\n",
      "\n",
      "The next most likely interesting article is:\n",
      "\n",
      "Realizing quantum optics in structured environments with giant atoms\n",
      "  To go beyond quantum optics in free-space setups, atom-light interfaces with\n",
      "structured photonic environments are often employed to realize unconventional\n",
      "quantum electrodynamics (QED) phenomena. However, when employed as quantum\n",
      "buses, those long-distance nanostructures are limited by fabrication disorders.\n",
      "In this work, we alternatively propose to realize structured lightmatter\n",
      "interactions by engineering multiple coupling points of hybrid giant\n",
      "atom-conventionalenvironments without any periodic structure. We present a\n",
      "generic optimization method to obtain the real-space coupling sequence for\n",
      "multiple coupling points. We report a broadband chiral emission in a very wide\n",
      "frequency regime, with no analog in other quantum setups. Moreover, we show\n",
      "that the QED phenomena in the band gap environment, such as fractional atomic\n",
      "decay and dipole-dipole interactions mediated by a bound state, can be observed\n",
      "in our setup. Numerical results indicate that our proposal is robust against\n",
      "fabrication disorders of the coupling sequence. Our work opens up a new route\n",
      "for realizing unconventional light-matter interactions.\n",
      "\n",
      "With an overlap in words of 17.86%\n"
     ]
    }
   ],
   "source": [
    "info = download_articles_of_day(day=None, num_articles=50)\n",
    "intreseting = show_subset_of_articles(info, num_articles_to_show=8)\n",
    "uniq = most_likely_interesting_articles(info, intreseting, 8, trivial_words_list_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416706b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nice things to maybe add: \n",
    "# -check manuallly  that the papers are interesting\n",
    "# -give the option to either only show titles or only show abstracts\n",
    "# -streamline interaction with user bit more\n",
    "# -write some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de07f7a6-7f11-4d73-b577-a91d7e0af08f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "['Symmetry', 'Fractionalized', '(Irrationalized)', 'Fusion', 'Rules', 'Two', 'Domain-Wall', 'Verlinde', 'Formulae']\n",
      "['Signatures', 'Fractional', 'Quantum', 'Anomalous', 'Hall', 'States', 'Twisted', 'MoTe2', 'Bilayer']\n",
      "['Effective', 'electric', 'field:', 'quantifying', 'sensitivity', 'searches', 'new', 'P,T-odd', 'physics', 'with', 'EuCl$_3\\\\cdot$6H$_2$O']\n",
      "['Big', 'Bang', 'initial', 'conditions', 'self-interacting', 'hidden', 'dark', 'matter']\n",
      "['Multi-Purpose', 'Platform', 'Analog', 'Quantum', 'Simulation']\n",
      "['Exciton', 'band', 'structure', 'V$_2$O$_5$']\n",
      "['first', 'application', 'machine', 'deep', 'learning', 'background', 'rejection', 'ALPS', 'II', 'TES', 'detector']\n",
      "['Search', 'gravitational-lensing', 'signatures', 'full', 'third', 'observing', 'run', 'LIGO-Virgo', 'network']\n",
      "['Detached', 'Continuous', 'Circumstellar', 'Matter', 'Type', 'Ibc', 'Supernovae', 'from', 'Mass', 'Eruption']\n",
      "['NvDEx-100', 'Conceptual', 'Design', 'Report']\n"
     ]
    }
   ],
   "source": [
    "title_paper_wordlist_nontrivial_paper = filter_nontrivial_words_from_papers(titles,trivial_words_list=trivial_words_list_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "651d4398-cd2c-447d-a894-5d6ce9699a06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "['interplay', 'between', 'spontaneous', 'symmetry', 'breaking', 'topology', 'result', 'exotic', 'quantum', 'states', 'matter.', 'celebrated', 'example', 'quantum', 'Hall', '(QAH)', 'state,', 'which', 'exhibits', 'an', 'integer', 'quantum', 'Hall', 'effect', 'magnetic', 'field', 'thanks', 'its', 'intrinsic', 'ferromagnetism.', 'presence', 'electron-electron', 'interactions,', 'exotic', 'fractional-QAH', '(FQAH)', 'states', 'magnetic', 'field', 'emerge.', 'These', 'states', 'could', 'host', 'fractional', 'excitations,', 'non-Abelian', 'anyons', '-', 'crucial', 'building', 'blocks', 'topological', 'quantum', 'Flat', 'Chern', 'bands', 'widely', 'considered', 'desirable', 'venue', 'FQAH', 'state.', 'this', 'purpose,', 'twisted', 'transition', 'metal', 'homobilayers', 'rhombohedral', 'stacking', 'have', 'recently', 'been', 'promising', 'material', 'platform.', 'Here,', 'report', 'experimental', 'FQAH', 'states', '3.7-degree', 'twisted', 'MoTe2', 'bilayer.', 'Magnetic', 'dichroism', 'measurements', 'reveal', 'robust', 'ferromagnetic', 'states', 'hole', 'filled', \"moir\\\\'e\", 'minibands.', 'Using', 'trion', 'photoluminescence', 'obtain', 'Landau', 'fan', 'diagram', 'which', 'shows', 'linear', 'shifts', 'carrier', 'corresponding', 'v=-2/3', '-3/5', 'ferromagnetic', 'states', 'with', 'magnetic', 'field.', 'These', 'shifts', 'match', 'Streda', 'formula', 'dispersion', 'states', 'with', 'fractionally', 'quantized', 'Hall', 'conductance', '-2/3$e^2/h$', 'respectively.', 'Moreover,', 'v=-1', 'state', 'exhibits', 'dispersion', 'Chern', 'number', '-1,', 'consistent', 'with', 'predicted', 'QAH', 'state.', 'several', 'non-ferromagnetic', 'states', 'electron', 'doping', 'side', 'do', 'i.e.,', 'trivial', 'correlated', 'insulators.', 'observed', 'topological', 'further', 'electrically', 'driven', 'into', 'topologically', 'trivial', 'states.', 'findings', 'provide', 'clear', 'evidence', 'long-sought', 'FQAH', 'states,', 'putting', 'MoTe2', \"moir\\\\'e\", 'superlattices', 'fascinating', 'platform', 'exploring', 'excitations.']\n",
      "['Laboratory-scale', 'precision', 'experiments', 'promising', 'approach', 'searching', 'physics', 'beyond', 'standard', 'model.', 'Non-centrosymmetric', 'solids', 'offer', 'statistical', 'sensitivity', 'efforts', 'search', 'new', 'fields,', 'whose', 'violate', 'discrete', 'parity', 'time-reversal', 'symmetries.', 'One', 'electric', 'Cosmic', 'Axion', 'Spin', 'Precession', 'Experiment', '(CASPEr-e),', 'sensitive', 'defining', 'interaction', 'QCD', 'axion', 'dark', 'matter', 'gluons', 'atomic', 'nuclei.', 'effective', 'electric', 'field', 'parameter', 'quantifies', 'sensitivity', 'such', 'experiments', 'new', 'physics.', 'describe', 'theoretical', 'approach', 'calculating', 'effective', 'electric', 'field', 'sites', 'ionic', 'insulating', 'solids.', 'consider', 'specific', 'EuCl$_3\\\\cdot$6H$_2$O', 'crystal,', 'which', 'particularly', 'promising', 'optimistic', 'estimate', 'effective', 'electric', 'field', 'isotope', 'this', 'crystal', '10', 'MV/cm.', 'calculation', 'uncertainty', 'two', 'orders', 'magnitude,', 'dominated', 'evaluation', 'nuclear', 'Schiff', 'moment.']\n",
      "['variety', 'supergravity', 'string', 'models', 'involve', 'hidden', 'sectors', 'where', 'sectors', 'may', 'couple', 'feebly', 'with', 'visible', 'sectors', 'via', 'variety', 'While', 'coupling', 'hidden', 'sector', 'visible', 'sector', 'its', 'coupling', 'inflaton', 'largely', 'unknown.', 'could', 'couple', 'feebly', 'with', 'same', 'strength', 'visible', 'sector', 'which', 'would', 'result', 'either', 'or', 'hot', 'hidden', 'sector', 'end', 'reheating.', 'These', 'two', 'possibilities', 'lead', 'significantly', 'different', 'outcomes', 'observables.', 'investigate', 'thermal', 'evolution', 'two', 'sectors', 'cosmologically', 'consistent', 'hidden', 'dark', 'matter', 'model', 'where', 'hidden', 'sector', 'visible', 'sector', 'coupled', 'their', 'thermal', 'evolution', 'occurs', 'without', 'assumption', 'entropy', 'conservation', 'each', 'sector.', 'Within', 'this', 'framework', 'analyze', 'phenomena', 'illustrate', 'their', 'dependence', 'initial', 'conditions.', 'include', 'allowed', 'parameter', 'space', 'models,', 'dark', 'matter', 'relic', 'density,', 'matter', 'cross', 'section,', 'effective', 'massless', 'neutrino', 'species', 'BBN', 'self-interacting', 'dark', 'matter', 'cross-section,', 'where', 'self-interaction', 'occurs', 'exchange', 'dark', 'photon,', 'Sommerfeld', 'enhancement.', 'Finally', 'fits', 'dependence', 'dark', 'matter', 'cross', 'sections', 'from', 'galaxy', 'scales', 'galaxy', 'clusters', 'given.', 'analysis', 'indicates', 'significant', 'effects', 'initial', 'conditions', 'observables', 'listed', 'above.', 'analysis', 'out', 'within', 'framework', 'where', 'dark', 'matter', 'constituted', 'dark', 'mediation', 'between', 'visible', 'hidden', 'sector', 'occurs', 'via', 'exchange', 'dark', 'photons.', 'techniques', 'discussed', 'here', 'may', 'have', 'wider', 'class', 'hidden', 'sector', 'models', 'using', 'different', 'between', 'visible', 'hidden', 'sectors', 'explore', 'impact', 'Bang', 'initial', 'conditions', 'observable', 'physics.']\n",
      "['Atom-based', 'quantum', 'simulators', 'have', 'had', 'tremendous', 'success', 'tackling', 'quantum', 'many-body', 'problems,', 'owing', 'precise', 'dynamical', 'they', 'provide', 'over', \"systems'\", 'parameters.', 'They', 'are,', 'however,', 'optimized', 'address', 'specific', 'type', 'problems.', 'Here,', 'present', 'implementation', '$^6$Li-based', 'quantum', 'gas', 'platform', 'provides', 'capabilities', 'able', 'address', 'variety', 'quantum', 'many-body', 'Our', 'two-chamber', 'architecture', 'relies', 'robust', 'easy-to-implement', 'gray', 'molasses', 'optical', 'transport', 'from', 'laser-cooling', 'chamber', 'glass', 'cell', 'with', 'excellent', 'optical', 'access.', 'There,', 'first', 'create', 'unitary', 'superfluids', 'three-dimensional', 'axially', 'symmetric', 'harmonic', 'trap', 'them', 'using', 'situ', 'thermometry,', 'reaching', 'temperatures', 'below', '20', 'nK.', 'allows', 'us', 'enter', 'deep', 'superfluid', 'regime', 'with', 'samples', 'extreme', 'where', 'interparticle', 'spacing', 'sufficiently', 'large', 'direct', 'imaging.', 'Secondly,', 'generate', 'optical', 'lattice', 'potentials', 'with', 'honeycomb', 'geometry', 'which', 'study', 'diffraction', 'molecular', 'condensates,', 'show', 'how', 'going', 'beyond', 'Kapitza-Dirac', 'regime', 'us', 'unambiguously', 'distinguish', 'between', 'two', 'geometries.', 'With', 'probe', 'quantum', 'many-body', 'physics', 'both', 'discrete', 'continuous', 'its', 'suitability', 'bulk', 'single-atom', 'imaging,', 'our', 'setup', 'an', 'important', 'step', 'towards', 'achieving', 'wide-scope', 'quantum', 'simulator.']\n",
      "['Excitonic', 'effects', 'due', 'correlation', 'electrons', 'holes', 'excited', 'matter', 'dominate', 'optical', 'spectra', 'many', 'interesting', 'materials.', 'usually', 'studied', 'long-wavelength', 'limit.', 'Here', 'investigate', 'non-vanishing', 'momentum', 'transfer,', 'corresponding', 'shorter', 'calculate', 'exciton', 'dispersion', 'prototypical', 'layered', 'V$_2$O$_5$', 'solving', 'Bethe-Salpeter', 'equation', 'many-body', 'theory.', 'discuss', 'change', 'excitation', 'energy', 'intensity', 'function', 'wavevector', 'bright', 'dark', 'excitons,', 'respectively,', 'origin', 'excitons', 'along', 'their', 'dispersion.', 'highlight', 'role', 'electron-hole', 'exchange', 'with', 'its', 'impact', 'exciton', 'singlet-triplet', 'splitting', 'difference', 'between', 'part', 'macroscopic', 'dielectric', 'function', 'loss', 'function.']\n",
      "['Axions', 'axion-like', 'particles', 'hypothetical', 'particles', 'predicted', 'standard', 'model', 'promising', 'cold', 'dark', 'matter', 'candidates.', 'Any', 'Light', 'Particle', 'Search', '(ALPS', 'II)', 'experiment', 'experiment', 'aims', 'produce', 'these', 'particles', 'strong', 'light', 'source', 'magnetic', 'field', 'subsequently', 'detect', 'them', 'reconversion', 'into', 'photons.', 'With', 'an', 'expected', 'rate', '$\\\\sim$', '1', 'photon', 'per', 'sensitive', 'detection', 'scheme', 'needs', 'employed', 'characterized.', 'One', 'detector', 'based', 'transition', 'edge', 'sensor', '(TES).', 'Here,', 'machine', 'deep', 'learning', 'algorithms', 'rejection', 'events', 'recorded', 'with', 'TES.', 'also', 'present', 'first', 'application', 'neural', 'networks', 'classify', 'time', 'series', 'data', 'measured', 'with']\n",
      "['Gravitational', 'lensing', 'massive', 'objects', 'along', 'line', 'sight', 'causes', 'distortions', 'gravitational', 'wave-signals;', 'such', 'distortions', 'may', 'information', 'about', 'fundamental', 'physics,', 'cosmology', 'astrophysics.', 'work,', 'have', 'extended', 'search', 'lensing', 'signatures', 'all', 'binary', 'hole', 'events', 'from', 'third', 'observing', 'run', 'LIGO--Virgo', 'network.', 'repeated', 'signals', 'from', 'strong', 'lensing', '1)', 'performing', 'targeted', 'subthreshold', 'signals,', '2)', 'calculating', 'degree', 'overlap', 'amongst', 'intrinsic', 'parameters', 'sky', 'location', 'pairs', 'signals,', '3)', 'comparing', 'spectrograms', 'amongst', 'pairs', 'signals,', '4)', 'performing', 'Bayesian', 'analysis', 'takes', 'into', 'account', 'selection', 'effects', 'knowledge.', 'also', 'search', 'distortions', 'gravitational', 'caused', '1)', 'frequency-independent', 'phase', 'shifts', 'strongly', 'lensed', '2)', 'frequency-dependent', 'modulation', 'amplitude', 'phase', 'due', 'masses.', 'None', 'these', 'searches', 'yields', 'significant', 'evidence', 'lensing.', 'use', 'non-detection', 'gravitational-wave', 'lensing', 'constrain', 'lensing', 'rate', 'based', 'latest', 'merger-rate', 'estimates', 'fraction', 'matter', 'composed', 'compact', 'objects.']\n",
      "['Some', 'hydrogen-poor', 'supernovae', '(SNe)', 'found', 'undergo', 'interaction', 'with', 'circumstellar', 'matter', '(CSM)', 'may', 'originate', 'from', 'mass', 'eruption(s)', 'just', 'core-collapse.', 'model', 'interaction', 'between', 'remaining', 'star', 'bound', 'part', 'erupted', 'CSM', 'eventually', 'fall', 'back', 'star.', 'while', 'fallback', 'initially', 'results', 'continuous', 'CSM', 'down', 'feedback', 'processes', 'from', 'star', 'push', 'CSM', 'large', 'radii', '10^{15}$', 'cm', 'from', 'several', 'years', 'eruption.', 'latter', 'case,', 'tenuous', 'bubble', 'surrounded', 'dense', 'detached', 'CSM', 'extending', '$\\\\gtrsim', 'cm', 'expected.', 'Our', 'model', 'offers', 'natural', 'unifying', 'explanation', 'diverse', 'CSM', 'structures', 'seen', 'hydrogen-poor', 'SNe,', 'such', 'Type', 'Ibn/Icn', 'SNe', 'show', 'CSM', 'signatures', 'soon', 'explosion,', 'recently', 'discovered', 'Type', 'SNe', '2021ocs', '2022xxf', '(\"the', 'Bactrian\")', 'with', 'CSM', 'signatures', 'seen', 'only', 'times.']\n",
      "['measurement', 'nuclear', 'neutrinoless', 'double-beta', 'decay', 'would', 'result', 'particle', 'physics.', 'observation', 'such', 'decay', 'would', 'neutrinos', 'their', 'own', 'antiparticles,', 'help', 'study', 'mass', 'neutrinos,', 'explore', 'origin', 'their', 'mass,', 'may', 'explain', 'matter-antimatter', 'asymmetry', 'our', 'universe', 'violation', 'lepton', 'propose', 'develop', 'time', 'projection', 'chamber', '(TPC)', 'using', '82SeF6', 'gas', 'top-metal', 'silicon', 'sensors', 'read-out', 'Jinping', 'Underground', 'Laboratory', '(CJPL),', 'search', 'neutrinoless', 'decay', '82Se,', 'called', 'NvDEx', 'experiment.', 'Besides', 'located', 'CJPL', \"world's\", 'deepest', 'rock', 'shielding,', 'NvDEx', 'combines', 'advantages', 'high', 'value', '(2.996', 'MeV)', '82Se', \"TPC's\", 'ability', 'distinguish', 'signal', 'events', 'using', 'their', 'different', 'topological', 'characteristics.', 'These', 'give', 'unique', 'great', 'potential', 'low', 'background', 'high', 'sensitivity.', 'NvDEx', 'experiment', 'phase', 'with', '100', 'kg', 'SeF6', 'gas,', 'being', 'built', 'planned', 'complete', 'with', 'installation', 'CJPL', 'around', 'year', '2025.', 'This', 'report', 'introduce', 'neutrinoless', 'double-beta', 'decay', 'physics,', 'NvDEx', 'concept', 'advantages,', 'schematic', 'design', 'NvDEx-100', 'its', 'sub-systems,', 'well', 'background', 'sensitivity', 'estimation', 'it.']\n"
     ]
    }
   ],
   "source": [
    "trivial_words_list_default = ['and','by','a','the','',  '','of','in','on','it','after',\n",
    "                              'for','ever','never','since','at','to','too','e.g.','are',\n",
    "                              'nm','is','as','we','i','go','not','can','be','that']\n",
    "\n",
    "summaries_papers_wordlist_nontrivial = filter_nontrivial_words_from_papers(summaries,trivial_words_list=trivial_words_list_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2ba05e0-1d01-4306-aff4-1a199aa11f28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_0_2304.08362v1.pdf\n"
     ]
    }
   ],
   "source": [
    "idlist_total = get_arxiv_id_papers(ids)\n",
    "\n",
    "\n",
    "save_articles_as_pdf(index_article_list =[0],ids=ids,save_papers=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
